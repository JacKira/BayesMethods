{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fa5749",
   "metadata": {},
   "source": [
    "<font color='red'> Если нет необходимых библиотек инсталируем их </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as torch_T\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ef959",
   "metadata": {},
   "source": [
    "# Лабораторная №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df21720",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = MNIST_train.train_data\n",
    "y_train = MNIST_train.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e902f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]\n",
    "np.array(map(lambda x: x[0] * x[1], list(enumerate(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e90de",
   "metadata": {},
   "source": [
    "# Выбор варианта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66c53f",
   "metadata": {},
   "source": [
    "Всего 60000 картинок, каждый выбирает картинки из диапазона $[6000(n-1)+1,6000\\cdot n]$ где $n$- номер по списку.\n",
    "Постройте гистограмму для ответов (y_train) и убедитесь, что у вас нет дисбаланса классов. Если есть дисбаланс, устраните его удалением соответствующего класса или удалением картинок. Порог для преобразования в $\\{0,1\\}$(см. ниже) установите равным:\n",
    "$$\n",
    "thr = 0.45 + (n-1)/100\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff4019",
   "metadata": {},
   "source": [
    "## Преобразуем данные в нули и единицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd30f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.45 # Номер варианта см. список группы\n",
    "X_train[X_train>thr] = 1\n",
    "X_train[X_train<thr] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42478ff9",
   "metadata": {},
   "source": [
    "## Картинка после преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a05fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0, :, :])\n",
    "plt.show()\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c7ae0",
   "metadata": {},
   "source": [
    "## Применим EM-алгоритм для смеси распределений Бернулли"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c1c6d",
   "metadata": {},
   "source": [
    "Найти выражения для E-шага и M-шага для смеси C штук распределений\n",
    "Бернулли \n",
    "$$\n",
    "p(X\\mid \\theta) = \\prod_{i=1}^D \\sum_{c=1}^C p (x_i|\\mu_c)\\pi_c, \\quad x_i\\in \\mathbf{R}^N,  \\quad \\mu\\in\\mathbf{R}^N\n",
    "$$\n",
    "$$\n",
    "p(z\\mid\\mu_c) = \\prod_{j=1}^N \\mu_{cj}^{z_j}(1-\\mu_{cj})^{1-z_j}, \\quad  z_j\\in\\{0,1\\},\n",
    "$$\n",
    "\n",
    "где параметры модели $\\theta = \\{\\mu_{11},\\dots,\\mu_{1N},\\dots,\\mu_{C1},\\dots,\\mu_{CN}, \\pi_1,\\dots, \\pi_C\\}$. \n",
    "\n",
    "<font color='red'> В отличие от модели на семинаре здесь параметр $\\mu$ это вектор размера $N$ !!! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79c79d",
   "metadata": {},
   "source": [
    "## Задание 1: получить выражения для E-шага"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259765a5",
   "metadata": {},
   "source": [
    "\n",
    "Получить формулы для E-шага. \n",
    "$$\n",
    "q(t_i) = p (t_i\\mid x_i,\\theta)\n",
    "$$\n",
    "$$\n",
    "\\gamma_{i,c} = q(t_i=c) = \\dots\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85823b",
   "metadata": {},
   "source": [
    "<b>Важный трюк 1:</b> при вычислении произведений, можно использовать логарифмирование, при этом, чтобы избежать нулей под логарифмом, можно нули заменять на очень маленькие числа. \n",
    "\n",
    "<b>Важный трюк 2:</b> важно избегать числовых ошибок. В какой-то момент вам может понадобиться вычислить формулу следующего вида (если использовать логарифмирование (см. трюк 1)): $\\frac{e^{y_i}}{\\sum_j e^{y_j}}$, которая называется _softmax_. Когда вы вычисляете показатели степени больших чисел, некоторые числа могут стать бесконечными. Этого можно избежать, разделив числитель и знаменатель на $e^{\\max(y)}$: \n",
    "$$\n",
    "\\frac{e^{y_i-\\max(y)}}{\\sum_j e^{y_j - \\max(y) )}}.\n",
    "$$ \n",
    "После этого преобразования максимальное значение в знаменателе будет равно единице. Все остальные члены будут вносить меньшие значения. Итак, чтобы вычислить нужную формулу, вы сначала вычитаете максимальное значение из каждой компоненты в векторе $\\mathbf{y}$, а затем вычисляете все остальное, как и раньше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebf767",
   "metadata": {},
   "source": [
    "## Задание 2: реализовать E-шаг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3181ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def E_step(X, pi, mu):\n",
    "        \n",
    "    eps = 1e-12\n",
    "\n",
    "\n",
    "    # def G_c_i(xi, pc, mc):\n",
    "    #     sum_ = 0\n",
    "    #     for j, x in enumerate(xi):\n",
    "    #         val = x * np.log(mc[j] + eps) + (1 - x) * np.log(1 - mc[j] + eps)\n",
    "    #         sum_ += val\n",
    "    #     sum_ += np.log(pc + eps)\n",
    "    #     return sum_\n",
    "\n",
    "    def G_c_i(xi, pc, mc):\n",
    "        return sum(list(map(lambda x: x[1] * np.log(mc[x[0]] + eps) + (1 - x[1]) * np.log(1 - mc[x[0]] + eps) , list(enumerate(xi))))) +  np.log(pc + eps)\n",
    "\n",
    "    \"\"\"\n",
    "    Performs E-step on GMM model\n",
    "    Each input is numpy array:\n",
    "    X: (D x N), data points\n",
    "    pi: (C), mixture component weights \n",
    "    mu: (C x N), mixture component means\n",
    "    \n",
    "    Returns:\n",
    "    gamma: (C x D), probabilities of clusters for objects\n",
    "    \"\"\"\n",
    "    D = X.shape[0] # number of objects\n",
    "    C = pi.shape[0] # number of clusters\n",
    "    N = mu.shape[1] # dimension of each object\n",
    "    gamma = np.zeros((C, D)) # distribution q(T)\n",
    "    log_g = np.zeros((C, D))\n",
    "    M = np.array([-1e6] * D)\n",
    "\n",
    "    print('\\tDefine log(g_c_i)')\n",
    "    # for c in range(C):\n",
    "    #     for i in range(D):\n",
    "    #         log_g[c][i] = G_c_i(X[i], pi[c], mu[c])\n",
    "    #         if(M[i] < log_g[c][i]):\n",
    "    #             M[i] = log_g[c][i]\n",
    "\n",
    "    # for c in range(C):\n",
    "    #     log_g[c] = np.array(list(map(lambda x: G_c_i(x, pi[c], mu[c]), X)))\n",
    "    #     M = np.array(list(map(lambda x: x[1] if x[1] >= log_g[c][x[0]] else log_g[c][x[0]], list(enumerate(M))))) \n",
    "\n",
    "    log_g = np.array(list(map(lambda c: np.array(list(map(lambda x: G_c_i(x, pi[c[0]], mu[c[0]]), X))), list(enumerate(log_g)))))\n",
    "    gc.collect()\n",
    "    for c in range(C):\n",
    "        M = np.array(list(map(lambda x: x[1] if x[1] >= log_g[c][x[0]] else log_g[c][x[0]], list(enumerate(M))))) \n",
    "    gc.collect()\n",
    "\n",
    "    EXP =np.zeros((C, D))\n",
    "    print('\\tDefine gamma')\n",
    "    # for c in range(C):\n",
    "    #     for i in range(D):\n",
    "    #         EXP[c][i] = np.exp(log_g[c][i] - M[i])\n",
    "\n",
    "\n",
    "    for c in range(C):\n",
    "        EXP[c] = np.array(list(map(lambda x: np.exp(x[1] - M[x[0]]), list(enumerate(log_g[c])))))\n",
    "    \n",
    "    gc.collect()\n",
    "    # for c in range(C):\n",
    "    #     for i in range(D):\n",
    "    #         gamma[c][i] = EXP[c][i] / (EXP.T[i].sum()+ eps)\n",
    "\n",
    "    for c in range(C):\n",
    "        gamma[c] = np.array(list(map(lambda x: x[1] / (EXP.T[x[0]].sum() + eps) , list(enumerate(EXP[c])))) )\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    #TO DO\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496916bb",
   "metadata": {},
   "source": [
    "## Задание 3:  получить выражения для M-шаг\n",
    "\n",
    "\n",
    "$$\n",
    "{\\cal L}(\\theta,q) = \\sum_i\\sum_c \\gamma_{i,c}\\left(\\sum_{j=1}^N x_{ij}\\log(\\mu_{cj}) + (1-x_{ij})\\log(1-\\mu_{cj})+ \\log\\pi_c\\right) \\to \\max_{\\theta}\n",
    "$$\n",
    "\n",
    "Составить функцию Лагранжа и получить выражения для $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167efb8",
   "metadata": {},
   "source": [
    "## Задание 4: реализовать M-шаг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(X, gamma):\n",
    "    \"\"\"\n",
    "    Performs E-step on GMM model\n",
    "    Each input is numpy array:\n",
    "    X: (D x N), data points\n",
    "    gamma: (C x D), probabilities of clusters for objects\n",
    "    Returns:\n",
    "    pi: (C)\n",
    "    mu: (C x N)\n",
    "    \"\"\"\n",
    "    D = X.shape[0] # number of objects\n",
    "    C = gamma.shape[0] # number of clusters\n",
    "    N = X.shape[1] # dimension of each object\n",
    "    eps = 1e-12\n",
    "    #TO DO\n",
    "    pi = np.zeros(C)\n",
    "    mu = np.zeros((C, N))\n",
    "    for c in range(C):\n",
    "        pi[c] = gamma[c].sum() / (gamma.sum() + eps)\n",
    "        for j in range(N):\n",
    "            mu[c][j] = (gamma[c] @  X.T[j]) / (gamma[c].sum() + eps)\n",
    "    \n",
    "    gc.collect()\n",
    "    return pi, mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3398523a",
   "metadata": {},
   "source": [
    "## Задание 5: получить функцию потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f0219",
   "metadata": {},
   "source": [
    "Наконец, нам нужна функция для отслеживания сходимости. Для этой цели мы будем использовать вариационную нижнюю границу $\\mathcal{L}$. Мы остановим наши итерации EM, когда $\\mathcal{L}$ перестанет сильно изменяться.  Также полезно проверить, что эта функция никогда не уменьшается во время тренировки. Если это так, у вас есть ошибка в вашем коде.\n",
    "\n",
    "<b>Реализуем функцию, которая будет вычислять $\\mathcal{L}$</b> \n",
    "\n",
    "$$\\mathcal{L}(\\theta, q) =\\mathbb{E}_{q(T)}\\log \\frac{p(X,T | \\theta)}{q(T|\\theta)}  =  \\dots$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4caad8",
   "metadata": {},
   "source": [
    "## Задание 6: реализовать функцию потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b936b",
   "metadata": {},
   "source": [
    "Не забываем использовать <b>трюк 1</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18442f4",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "{\\cal L}(\\theta,q) = \\sum_c\\sum_i \\gamma_{c,i}\\left(\\sum_{j=1}^N x_{ij}\\log(\\mu_{cj}) + (1-x_{ij})\\log(1-\\mu_{cj})\\right)+ \\log\\pi_c \\to \\max_{\\theta}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d52039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vlb(X, pi, mu, gamma):\n",
    "    \"\"\"\n",
    "    Each input is numpy array:\n",
    "    X: (D x N), data points\n",
    "    gamma: (C x D), distribution q(T)  \n",
    "    pi: (C)\n",
    "    mu: (C x N)\n",
    "    sigma: (C x N x N)\n",
    "    \n",
    "    Returns value of variational lower bound\n",
    "    \"\"\"\n",
    "    D = X.shape[0] # number of objects\n",
    "    C = gamma.shape[0] # number of clusters\n",
    "    N = X.shape[1] # dimension of each object\n",
    "    eps =1e-9\n",
    "    #TO DO\n",
    "\n",
    "    loss = 0\n",
    "    for c in range(C):\n",
    "        for i in range(D):\n",
    "            sum_ = 0\n",
    "            for j in range(N):\n",
    "                sum_ += X[i][j] * np.log(mu[c][j] + eps) + (1 - X[i][j]) * np.log(1 - mu[c][j] + eps)\n",
    "\n",
    "            loss += sum_+ np.log(pi[c] + eps)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c07878",
   "metadata": {},
   "source": [
    "## Задание 7: внедрение процедуры обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263f29b",
   "metadata": {},
   "source": [
    "Теперь, когда у нас есть шаг E, шаг M и VLB, мы можем реализовать тренировочный цикл. Мы будем инициализировать значения $\\pi$, $\\mu$ и $\\Sigma$ некоторыми случайными числами, обучать до тех пор, пока $\\mathcal{L}$ не перестанет меняться, и возвращать полученные точки. Мы также знаем, что алгоритм EM сходится к локальным оптимумам. Чтобы найти лучшие локальные оптимумы, мы перезапустим алгоритм несколько раз с разных (случайных) начальных позиций. Каждое тренировочное испытание должно останавливаться либо при достижении максимального количества итераций, либо когда относительное улучшение становится меньше заданного допуска $$\\left|\\frac{\\mathcal{L}_i-\\mathcal{L}_{i-1}}{\\mathcal {L}_{i-1}}\\right| \\le \\text{rtol}$$.\n",
    "\n",
    "<b>Начальные данные:</b>\n",
    "Параметры $\\pi_c$ можно задавать одинаковыми, при это не забываем, что сумма равна единице.  Параметры $\\mu$ можно моделировать равномерно на отрезке [0.25, 0.75], далее их надо отнормировать.\n",
    "\n",
    "Также в код можно добавить обработку ситуации, когда целевая функция возвращает nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_pi(C):\n",
    "    pi = np.zeros(C)\n",
    "    #TO DO\n",
    "    return pi\n",
    "\n",
    "def rand_mu(X, C, N):\n",
    "    #print('\\n', type(X), '\\n', type(C), '\\n', type(N))\n",
    "    mu = np.ones((C,N))\n",
    "    mu = np.abs(np.random.normal(size=(C, N)))\n",
    "    mu /= mu.sum()\n",
    "    # TO DO\n",
    "    return mu\n",
    "\n",
    "\n",
    "def train_EM(X, C=10, rtol=1e-3, max_iter=10, restarts=10):\n",
    "    '''\n",
    "    Starts with random initialization *restarts* times\n",
    "    Runs optimization until saturation with *rtol* reached\n",
    "    or *max_iter* iterations were made.\n",
    "    \n",
    "    X: (D, N), data points\n",
    "    C: int, number of clusters\n",
    "    '''\n",
    "    N = X.shape[0] # number of objects\n",
    "    d = X.shape[1] # dimension of each object\n",
    "    print(N, '\\n', d)\n",
    "    best_loss = None\n",
    "    best_pi = None\n",
    "    best_mu = None\n",
    "    best_sigma = None\n",
    "    loss_prev = None\n",
    "    losses = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for _ in range(restarts):\n",
    "        print('New restart')\n",
    "        loss = None\n",
    "        curr_rel_loss = None\n",
    "        pic = np.abs(np.random.normal(size=C))\n",
    "        pi0 = pic / pic.sum()\n",
    "        mu0 = rand_mu(X, C, d) \n",
    "        loss = None\n",
    "        for i in range(max_iter):\n",
    "            gc.collect()\n",
    "            pi, mu = pi0, mu0\n",
    "            print('\\nRun E - step')\n",
    "            gamma = E_step(X, pi, mu)\n",
    "            print('Run M - step')\n",
    "            pi, mu  = M_step(X, gamma)\n",
    "            print('Define Loss')\n",
    "            loss = compute_vlb(X, pi, mu, gamma)\n",
    "            print(f'Loss {loss:.2f}\\n')\n",
    "            losses.append(loss)\n",
    "            pi0 = pi\n",
    "            mu0 = mu\n",
    "            if loss_prev != None:\n",
    "                curr_rel_loss = np.abs(loss_prev - loss)/np.abs(loss_prev)\n",
    "                loss_prev = loss\n",
    "            else:\n",
    "                loss_prev = loss\n",
    "            if curr_rel_loss!=None and curr_rel_loss < rtol:\n",
    "                break\n",
    "            print(f'Step: {i}')\n",
    "        if best_loss!=None:\n",
    "            if loss>best_loss:\n",
    "                best_loss = loss\n",
    "                best_mu = mu\n",
    "                best_pi = pi\n",
    "        else:\n",
    "            best_loss = loss\n",
    "            best_mu = mu\n",
    "            best_pi = pi\n",
    "\n",
    "    return  losses, best_pi, best_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses, pi, mu = train_EM(np.array([X_train.reshape(-1, 28*28)[0]]), restarts= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d038e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "545f21a5",
   "metadata": {},
   "source": [
    "## Задание 8\n",
    "\n",
    "Обучить модель и ответить на следующие вопросы.\n",
    "\n",
    "1. Построить графики для всех математических ожиданий в виде цифр (т.е. преобразовать вектора в матрицы) Похожи ли получившиеся средние на цифры? (С=10)\n",
    "2. Построить несколько картинок для цифр из обучающей выборки и соответствующих математических ожиданий на одном графике для одного класса. Проделать это для нескольких классов. Как можно интерпретировать результат?\n",
    "3. Разбить на обучающую и тестовую выборки, и определить оптимальное кол-во кластеров с помощью графиков правдоподобия для обучения и теста. \n",
    "4. Попробовать улучшить результат (варьировать различные параметры), подумать как оценивать качество.\n",
    "5. Написать вывод.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "thr = 0.45 + (n - 1) / 100 # Номер варианта см. список группы\n",
    "X_train_var = X_train[6000*(n-1): 6000*n]\n",
    "Y_train_var = y_train[6000*(n-1): 6000*n]\n",
    "X_train_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43976964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var[X_train_var > thr] = 1\n",
    "X_train_var[X_train_var < thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88547a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_var[0])\n",
    "plt.show()\n",
    "sns.histplot(Y_train_var, bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a912e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var.reshape(-1, 28*28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c54240",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "losses, pi, mu = train_EM(X_train_var.reshape(-1, 28*28), restarts= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff854de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu[mu > thr] = 1\n",
    "mu[mu < thr] = 0\n",
    "fig, ax = plt.subplots(len(mu), 1, figsize = (len(mu) * 20, 20))\n",
    "for i, v in enumerate(mu):\n",
    "    ax[i].imshow(v.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d02b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec26487",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a51140",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = E_step(np.array([X_train.reshape(-1, 28*28)[8]]), pi, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868db003",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pi, new_mu = M_step(np.array([X_train.reshape(-1, 28*28)[8]]), gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a81e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mu[np.argmax(new_pi)].reshape(28, 28)\n",
    "pred[pred >= thr] = 1\n",
    "pred[pred < thr] = 0\n",
    "plt.imshow(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
