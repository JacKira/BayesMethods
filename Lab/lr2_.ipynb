{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G233yNiDOnLp"
      },
      "source": [
        "# Google colab\n",
        "* Выбрвать **File -> Save a copy in Drive**, нажмите **Open in new tab** во всплывающем окне, чтобы сохранить свой прогресс на Google Диске.\n",
        "* Нажмите **Runtime -> Change runtime type** и выберите **GPU** в поле Аппаратный ускоритель (Hardware accelerator), чтобы включить ускоренное обучение на графической карте (GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74KEu1L8OnLq"
      },
      "source": [
        "# Вариационный автокодировщик"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r94_BRA-OnLr"
      },
      "source": [
        "Здесь мы создадим вариационный автокодировщик (autoencoder), обучите его на наборе данных MNIST и поиграете с его архитектурой и гиперпараметрами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyLQLqBcOnLt"
      },
      "source": [
        "\n",
        "### Настройка\n",
        "Загрузка вспомогательных файлов и импорт необходимых библиотек."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MqsXAwczlQNp"
      },
      "outputs": [],
      "source": [
        "#%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H-hJ6_wBOnLz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Input, Dense, Lambda, InputLayer, concatenate, BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras import metrics\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import tensorflow.compat.v1.keras.backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnkOQUeSOnL5"
      },
      "source": [
        "### Вариационный автокодировщик"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmV9OxiIOnL7"
      },
      "source": [
        "Напомним, что вариационный автоэнкодер — это вероятностная модель данных, основанная на непрерывной смеси распределений. В лекции мы рассмотрели случай смеси гауссиан, но здесь мы применим ВА (VAE) к бинарным изображениям MNIST (каждый пиксель либо черный, либо белый). Чтобы лучше моделировать двоичные данные, мы будем использовать непрерывную смесь биномиальных распределений: $$p(x \\mid w) = \\int p(x \\mid t, w) p(t) dt,$$ где априорное распределение скрытой переменной $t$ — стандартное нормальное $p(t) = \\mathcal{N}(t\\mid 0, I)$, но вероятность того, что $(i, j)$-й пиксель черный, равна $(i, j)$-му выходу нейронной сети декодера: $$p(x_{i, j} \\mid t, w) = \\text{decoder}(t, w)_{i, j}.$$\n",
        "\n",
        "Чтобы обучить эту модель, мы хотели бы максимизировать неполное логарифмическое правдоподобие нашего набора данных $$\\max_w \\log p(X \\mid w),$$ но это очень сложно сделать в вычислительном отношении, поэтому вместо этого мы максимизируем вариационную нижнюю границу  как для исходных параметров $w$, так и для распределений $q$, которое мы определяем как кодирующую нейронную сеть (encoder) с параметрами (весами) $\\phi$, которая принимает входное изображение $x$ и выводит параметры гауссовского распределения $$q(t \\mid x, \\phi ): \\log p(X \\mid w) \\geq \\mathcal{L}(w, \\phi) \\rightarrow \\max_{w, \\phi}.$$\n",
        "\n",
        "Итак, в целом наша модель выглядит следующим образом: кодировщик (encoder) берет изображение $x$, выдает распределение по скрытым кодам $q(t\\mid x)$, которое должно аппроксимировать апостериорное распределение $p(t\\mid x)$ (по крайней мере, после обучения), моделирует точку из этого распределения $\\widehat{t} \\sim q(t \\mid x, \\phi)$ и, наконец, передает ее в декодер, который выводит распределение над изображениями.\n",
        "\n",
        "![](https://github.com/hse-aml/bayesian-methods-for-ml/blob/master/week5/VAE.png?raw=1)\n",
        "\n",
        "В лекции мы также обсудили, что вариационная нижняя граница имеет математическое ожидание, которое мы собираемся аппроксимировать усреднением по выборкам. Но это не тривиально, поскольку нам нужно дифференцировать это приближение. Тем не менее, мы узнали о трюке _репараметризации_, который предлагает вместо выборки из распределения $\\widehat{t} \\sim q(t \\mid x, \\phi)$ брать выборку из распределения, которое не зависит ни от каких параметров, например, стандартное нормальное, а затем детерминистически преобразовать эту выборку в нужную: $$\\varepsilon \\sim \\mathcal{N}(0, I),\\quad \\widehat{t} = m(x, \\phi) + \\varepsilon \\sigma(x, \\phi).$$ Таким образом, нам не нужно беспокоиться о смещении нашего стохастического градиента, и мы можем напрямую дифференцировать нашу функцию потерь  по всем параметрам, считая текущую выборку $\\varepsilon$ постоянной.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMuhWEYBOnMt"
      },
      "source": [
        "# Условный VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly1YYFktOnMu"
      },
      "source": [
        "В последнем задании мы изменним свой код, чтобы получить условный вариационный автоэнкодер [1]. Идея очень проста: чтобы иметь возможность контролировать сгенерированные вами выборки, мы обусловливаем все распределения некоторой дополнительной информацией. В нашем случае этой дополнительной информацией будет метка класса (цифра на изображении, от 0 до 9).\n",
        "\n",
        "![](https://github.com/hse-aml/bayesian-methods-for-ml/blob/master/week5/CVAE.png?raw=1)\n",
        "\n",
        "Итак, теперь и вероятность, и вариационное распределение зависят от метки класса: $p(x \\mid t, \\text{label}, w)$, $q(t \\mid x, \\text{label}, \\phi )$.\n",
        "\n",
        "Единственное, что вам нужно изменить в своем коде, это объединить входное изображение $x$ с (one-hot) меткой этого изображения для передачи в кодировщик $q$ и объединить скрытую переменную $t$ с той же меткой для передачи в декодер $p$. Обратите внимание, что это немного сложнее сделать со сверточной моделью кодера/декодера.\n",
        "\n",
        "[1] Sohn, Kihyuk, Honglak Lee, and Xinchen Yan. “Learning Structured Output Representation using Deep Conditional Generative Models.” Advances in Neural Information Processing Systems. 2015."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GPFxR6cOnNV"
      },
      "source": [
        "# Лабораторная работа №2\n",
        "Измените приведенный выше код для работы со смесью распределений Гаусса (в отличие от смеси биномиальных распределений) и повторите эксперименты с набором данных CIFAR-10, которые представляют собой полноцветные естественные изображения с гораздо более разнообразной структурой."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задача 1 \n",
        "Получим вариационную нижнюю границу для непрерывной смеси распределений Гаусса.\n",
        "$$\n",
        "{\\cal L(w,q)} = VLB =   \\sum_{i=1}^N \\text{VLB}_i =  \\sum_i\\mathbf{M}_{q_i}\\log\\frac{p(x_i\\mid t_i, w) p(t_i)}{q_{i}(t_i)} = \\sum_i \\mathbf{M}_{q_i} \\log p(x_i\\mid t_i, w)  +  \\underbrace{\\mathbf{M}_{q_i}\\log \\frac{p(t_i)}{q_i(t_i)}}_{-D_{kl}(q_i(t_i)|| p(t_i))}\n",
        "$$\n",
        "$$\n",
        "\\begin{align*}\n",
        "D_{kl}(q_i(t_i)|| p(t_i)) &= \n",
        "\\\\\n",
        "&=\\sum_{j=1}^M\\left(-\\log\\sigma(t_i) + \\frac{\\sigma^2(t_i) +\\mu^2(t_i)-1}{2}\\right) = M\\left(-\\log\\sigma(t_i) + \\frac{\\sigma^2(t_i) +\\mu^2(t_i)-1}{2}\n",
        "\\right)\n",
        "\\end{align*}\n",
        "$$\n",
        "Первый член в выражении для ${\\cal L(w,q)}$:\n",
        "\\begin{align*}\n",
        "\\sum_i\\mathbf{M}_{q_i}\\log p(x_i\\mid t_i, w)  = \n",
        "\\sum_i \\int q_i(t_i)\\log \\prod_j \\sqrt{\\frac{1}{2πσ^2(t_i)}}e^{-\\frac{(x_{ij}-μ(t_i))^2}{2σ^2(t_i)}} =\n",
        "\\sum_i(M_{q_i}[-\\frac{N}{2}\\log(2πσ^2(t_i))] -  M_{q_i}[\\frac{{\\lVert x_{i}-μ(t_i)}\\rVert^2}{2σ^2(t_i)}])\n",
        "\\end{align*}\n",
        "Получаем:\n",
        "$$\n",
        "VLB_i =\\mathbf{M}_{q_i}\\left\\{\\sum_i(-\\frac{N}{2}\\log(2πσ^2(t_i)) - \\frac{{\\lVert x_{ij}-μ(t_i)}\\rVert^2}{2σ^2(t_i)}) + M\\left(-\\log\\sigma(t_i) + \\frac{\\sigma^2(t_i) +\\mu^2(t_i)-1}{2}\\right)\\right\\}\n",
        "$$"
      ],
      "metadata": {
        "id": "PUu09jqY4SeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Input, Dense, Lambda, InputLayer, concatenate, BatchNormalization, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras import metrics\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import tensorflow.compat.v1.keras.backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "zwO7iRg7alm5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eUrScYEVviWT",
        "outputId": "dae88537-3793-477c-d80d-29ad308a222e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start tf session so we can run code.\n",
        "#sess = tf.InteractiveSession()\n",
        "sess=tf.compat.v1.InteractiveSession()\n",
        "# Connect keras to the created session.\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "dsz5vSmwal90"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W-Gv4MoqOnNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51401e34-39c8-4231-82a5-a9351a5205b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10\n",
        "from PIL import Image\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "w_dim = x_train[0].shape[0]\n",
        "h_dim = x_train[0].shape[1]\n",
        "c_dim = x_train[0].shape[2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haLwW4Hyvvw-",
        "outputId": "2806e163-14b4-4148-d624-6e595a64a998"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[7, :])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "WHa85E9x0PPh",
        "outputId": "628bd1c5-cc3b-41e0-f51c-1c21b1861a4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdbUlEQVR4nO2dW4xlZ5Xf/2ufe9364rK7e7qdNBjmYo0yBnU8TIaMmGFm5DAjGaQIwQPyA5oeRYMUpMmDRaRApDwwUQDxRNQEazwR4ZLBBCtCCcQaiRBpPLTB2I1tjLHbYNP36kvdzmXvvfJwjqO28/1XVXdVnfL4+/+kVlftVd/ea397r7PP+f5nrWXuDiHEG59itx0QQkwHBbsQmaBgFyITFOxCZIKCXYhMULALkQnNrQw2s3sAfBZAA8B/cvdPRn/f6XZ8Zm72xg9E5EEHlw0NFtg4ZtHrHxsZ+GGBraipra75OHd+Bk53yc/L+SDUgS0675tSdIMx0bWOjsWk5UhyDuXocBwfZsFNR691dCwyH1VZoa7r5NHsZnV2M2sAeBbAHwB4CcD3AHzQ3Z9iY/Yt7vd3/9HvJ23xxUzbyrKkY5rB7DaDG7/d5i9GxsbZiI5ptLit3R1S2/r6gNpGgwa3DdO2umrTMWXFfeyXq9RWVdz/uk6/SEQvVHXF74GyjGwVtY1G6XNj2zey1SN+zzk5ZwAogvtxMEzPYxn4we79yxcvYzQcJQ+2lbfxdwN4zt2fd/chgC8DuHcL+xNC7CBbCfbDAH5+3e8vTbYJIV6H7PgCnZkdN7OTZnZy0OdvTYUQO8tWgv1lALdf9/uRybZX4e4n3P2Yux/rdDtbOJwQYitsJdi/B+CtZvYmM2sD+ACAh7fHLSHEdnPT0pu7l2b2EQD/E2Pp7QF3/1E0xgBYQVYlQ9kiEsuYf3xlNNIf3PnKbkEWwSvnq9LlkK9mo8mP1Wrzcy5HwcchMlc1oo9Q/FiNUIpsUYvX6ZXkRrC7kQer4MGKOyKZkikNxD8AsJqvuFsd+RHIlME9zPbZZLECoN1OqytXQxVqC7j7NwF8cyv7EEJMB32DTohMULALkQkKdiEyQcEuRCYo2IXIhC2txt8ojiBBIpJPiFgWZYbVQXJHs82/3FMHssu1a0vJ7e0ul1yanSDJZLBObXOzPCFnfi+XvJavpfc5WuHHQsGTZIoggaYK5h8kqaUOpM1q1Kc2C5JkUAYyK5EpLUpaCXxsBHJYo8mvSyuwebeb3E5lagBNIoleOH+JjtGTXYhMULALkQkKdiEyQcEuRCYo2IXIhKmuxgM8qcWDWm0sc6URZFVEZYyicdEK+S/O/jy5/Y63HKRjZmf5FK/1eQJNf8hVgfm5eWpb2EsMDb6//ipPkqlImSsAKIdRXTuy+hwkkliwCh6tnreCR1a7l1YTGg1+XgXLeALQanB1omHBPoMEFaYq1WHSTXpMeF58b0KINxIKdiEyQcEuRCYo2IXIBAW7EJmgYBciE6abCOOOsiJywk10prmZ2nQAUJZBzbjA1mqR+m5BDbrllTVqWx9coTaAJ9Asr1ygttm5dFJF0eTz25kJEj+MS02DPn9WGJHeGg2eELJngScoFYEK1Wzw2ziSohhRZ5dGUHcPUVuu4P5m3V2izjTDQfqeiyJCT3YhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkwpakNzM7DWAZQAWgdPdj4QB3VGVaTojqyTGFLcpOiqSOtTUuh1UVzw7bs2cuuX155TL3o+Dtn4oGzzYrIq0pmKvVNXY8LuM0gozDXncftR04eBu1dZppW2FcuioCP5pB066aSFcAUBTp59loxMeUga0IpLdqxCW7wYBf63KYtg2DMWx/Uduz7dDZf9fdL27DfoQQO4jexguRCVsNdgfwLTN7zMyOb4dDQoidYatv49/p7i+b2W0Avm1mz7j7d67/g8mLwHEA6M30tng4IcTNsqUnu7u/PPn/PICvA7g78Tcn3P2Yux9rd/j3rIUQO8tNB7uZzZrZ/Cs/A/hDAKe2yzEhxPaylbfxBwB8fZJ51gTwX9z9f0QDHI6aSFt1IBmw1lBMVgGAqH7lyhKXwy5dOkdtXVLncd8R/o6lbPIClk3jEk90ApFEVRJJptPmMuV8J8o2C+TB9gq1zc2lz7vZmKFjVta43FjWPLOw2eC5Xi3yPBsNgjnkXagwrLmEOSKyMgCUQ77TirSoYtuBoDhnIDnfdLC7+/MAfuNmxwshpoukNyEyQcEuRCYo2IXIBAW7EJmgYBciE6bb680dVZWWJ+LikWk5waNMqCADqQz6qHmQQbW2mpbs2gMuvVVB1luzCvqXBcULi0CmbJM+dtYMeoDV3NZr8VtkdXCJ2i5fTUtNM7OBnNRcoLZ20NAtmo+VS1eT28v14H6r0kU7gfiei+TSSB5skmeuGz9ndn8XwWnpyS5EJijYhcgEBbsQmaBgFyITFOxCZMJ0V+MBFDfe5QkNUmuuEyRwtGf4qR098kvUduXSLdT29HOPJbc7URiA+Hxne3uobb6brncHAB4kY7TJqm+wGIz1wTK1FUWgGHT5s2JUpVfjV9Z+Rse0u3v5sQp+raP2T61e+gIE+T3oBsk67UBBGZU8kadiiSsAQNSEosPr3TW7aQWoSdQYQE92IbJBwS5EJijYhcgEBbsQmaBgFyITFOxCZMJUpbdG0cD8bFpS6vV4memFhXSCxMI8T5yYX5iltn17SDE5AD/43t9SW+vFtATYDPQ1B08yaRY84WLPApcAm02uo3U66Us6HPAaaCtXuJRXFVGLKi5DNchpe8llvrLm9foK59ezUXCprEuutVVBYlBQC68Bfs6IaiJ2+LU2MFkx0G2JBNgIfNCTXYhMULALkQkKdiEyQcEuRCYo2IXIBAW7EJmwofRmZg8A+GMA59391yfb9gP4CoCjAE4DeL+7X95oX91uF7/2y7+StM3N8Syv2dm07BJlvTWCdkdFcNaXr16jNvf0a2OnxWvQrQ54TbuL13j7pD2zPANsfg+XoZrt9Jx4kA2FNZ5d5UG2lgcyT12l2zU1GkH2F4L2SSM+jxW4PFg2iUTV4vdbt8tl4Lkuv+es5jdWRVqYAUBJZLSqDtphgdiCWo6bebL/JYB7XrPtfgCPuPtbATwy+V0I8Tpmw2Cf9Ftfes3mewE8OPn5QQDv3Wa/hBDbzM1+Zj/g7mcmP5/FuKOrEOJ1zJYX6NzdEXyvz8yOm9lJMzu5trq21cMJIW6Smw32c2Z2CAAm/59nf+juJ9z9mLsfm5nl32EWQuwsNxvsDwO4b/LzfQC+sT3uCCF2is1Ib18C8C4Ai2b2EoCPA/gkgK+a2YcBvAjg/Zs5WKvVxKGDB4mNyz8FkY1YIUoAqKPuPkEyUaPJs5OGg/TAlvF3LPO9oH1SxbO86kDyKoKst/NLF5PbOzNcMio6XDos+1zyalsgQ1n6vOuKf5RrEZkMADxoh7U64PssSdZhK7gJus6vWbvJ5wrG78eouVlNPgVXzvdXEpkyque6YbC7+weJ6d0bjRVCvH7QN+iEyAQFuxCZoGAXIhMU7EJkgoJdiEyYasFJg6FBKhFaIE4YkV1GQ54lNQoKA5aBDnLw4BFqe+rJdDZU2ecSyeLirdR26DYur/XmuKw1N8elvgGR89aHq3RMK8iIc+OSaKvNC35Wg3TWW1kG4lDNZb6GcR+rQM6rR2k/5md4n736CpdEhyM+950gky6sHUmy3tZH/P5YWU/b6qgeJjcJId5IKNiFyAQFuxCZoGAXIhMU7EJkgoJdiEyYqvRWOzAoiTYQZHkZkS2qkks1LJNoI9tt+3mPtaNHjia3v3D6WTqmGfR6u+0fcPnHKn5pPJCv9s2n5Z8LS7y4pVV8HpuB5FU0uY8lSTt059JV5bxwZA3uY1BjERWR3oo5Pqjqcdu1FS7LzRS8UOX6iO9zpZ+WkJdX+bHW1tI2VrwS0JNdiGxQsAuRCQp2ITJBwS5EJijYhciE6a7G1xWuraUTMsz5CnODvCZFr1RFsELbavGRvQXeWum3fvM3k9vng5ZAFy/Rwrs49f3nqW1uH691dvj2eWprddOr1nXVp2PawXw029yPosWVhjZpQ4U+v84VqfEHAKh50pMF6oqRtksr6zwxqN3mKsnVEVc11iueNDQYcdvycvra9Af8mpkzdYLPhZ7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyITNtH96AMAfAzjv7r8+2fYJAH8C4MLkzz7m7t/caF8OR0UkoKjGmBFbs8Hd7wZyWKfDZZDRgCcf7NmbTuL43Xf/UzrmmWeeoraL/+cS92OFJwYtdPZTW1UtJ7dbxfcXdTTq9nhyR5sk3QDAiORjkBKEAID1Op20AgBDniMDC3ZaEClqNZDeGnP8vAbGHVlfSbfeAgCUvK1Yg4Th3h6/MK1G+v5uBvUEN/Nk/0sA9yS2f8bd75r82zDQhRC7y4bB7u7fAbA0BV+EEDvIVj6zf8TMnjCzB8xs37Z5JITYEW422D8H4A4AdwE4A+BT7A/N7LiZnTSzk6urvL63EGJnualgd/dz7l65ew3g8wDuDv72hLsfc/djs7O8SokQYme5qWA3s0PX/fo+AKe2xx0hxE6xGentSwDeBWDRzF4C8HEA7zKzuzBOsTkN4E83czAD0CQqSa/N5bAuyaDqBppRs8VPLapdd/kyl8POn385uf3OX/tlOubw0YPU9kezv09tS0t8TXQ+aA3lls6IW7r8Eh9Tc7lxFEh2Tuq7jf1IX8+o/l+UqujG5TVr8HunKNIaYH+d3wPDip9X0Quej3yqsLfJsymbQ7LPEfdxdZVk3wX9nzYMdnf/YGLzFzYaJ4R4faFv0AmRCQp2ITJBwS5EJijYhcgEBbsQmTDVgpNFo8D8bFqCaAcZbK0ibWsW/LWqHcgxvXleUHDPXl7McW2Qzii75eCtdMyvLnJZ7pnH+dcTDi7yff742R9T29E3/VJye7vJJZkzV3nhy5r13gLQD1LRGqSIJfcCQMHltVabZ9+VgeRV10S+KoIMu4qfV6vLM+JQcv+7pB0WAIxIK6el87xY6ZXlq+l9DQPZkFqEEG8oFOxCZIKCXYhMULALkQkKdiEyQcEuRCZMV3pDgU4jXXiv1+GZXAtzaTnsln288OLBQ0eobd/+RWqbmeWS3eKB9LhnnnuS+3H4Nmq75ba91NYNsqROPc2LWFZEKesFtQQaa/w2GAZZVEH+GsalDv5/LOjB1wwyH+ugUCVK7slwlC6YYkF/u1FQ+LIdFcy8xotYXljituFSugjrelD81KJmhgQ92YXIBAW7EJmgYBciExTsQmSCgl2ITJjqanyn08Vb7viVpO3AIl+1vnUxvQq+sMATWppN3m5n0OerrVF7orvuOpbc/tzPfkLHPPUcT1pZCGZ/di9PhGkFbYFeOvuL5PZDh3kiSbPDHenXQd+lYD2+rtPZKUWQChO182oESU+NJvejIivrjSav7zYa8syawVp65RwA1oIV9+Ii32drlD5vK/h1NnbOgdyhJ7sQmaBgFyITFOxCZIKCXYhMULALkQkKdiEyYTPtn24H8FcADmCstZxw98+a2X4AXwFwFOMWUO9398vRvmZnZ3H3P/4nSVuHtHgCAPO0zGDGX6tW19L14gDgbx/9LrV5c0RtexbTySRX+xfomMtXeR2xAzM8EebKtWvU1tjDpcO1tfQlWC35mGZQ+60d3CIe1KerjUhvzqWhlvPrGT2VRsE+mTzodeB7GST/rHPbXJPLm4MGT2ppID3/DXLfA4DX/D5lbObJXgL4c3e/E8A7APyZmd0J4H4Aj7j7WwE8MvldCPE6ZcNgd/cz7v79yc/LAJ4GcBjAvQAenPzZgwDeu1NOCiG2zg19ZjezowDeBuBRAAfc/czEdBbjt/lCiNcpmw52M5sD8DUAH3X3V32gdHcH+XBkZsfN7KSZnbx4kbdDFkLsLJsKdjNrYRzoX3T3hyabz5nZoYn9EIDkSpS7n3D3Y+5+bHHxlu3wWQhxE2wY7GZmGPdjf9rdP32d6WEA901+vg/AN7bfPSHEdrGZrLffBvAhAE+a2eOTbR8D8EkAXzWzDwN4EcD7N9qRWYE2ldi4fOIkk6cIsqTWBivU9r8f/Ra1Xbp6jto6C+nXxvWKy2Qzs1xS7F/hSuXa8Aq1rdaBwknaPJ29wLO1fMAzstpBTT4LMqwqIr1FxeSaga0ecv/X+/xaD6u0RFUG54w+P6/2iD8foyzM5RE/t/VraVmuFbhYVGk/IhFyw2B39+8G+3j3RuOFEK8P9A06ITJBwS5EJijYhcgEBbsQmaBgFyITplpwEgZUQaYUo67SGsTqCpe8XnjxZ8H+uAzS6aRbTQFA09Ky1sqVi3TM0qUlaiuHgc3SbYsAwIKqmG1Pyz+rZ3nhyMEyzxA8/OYFamsFl7JupAs6Oq/zCBsG8iu5BwDAWlzenO2kpcNWyeejXONOWiDZdXo8nNqL+6jtzHral6rmfjSaRHpTwUkhhIJdiExQsAuRCQp2ITJBwS5EJijYhciEqUpvVV1heZDuh3XhPC/a+MLpF5LbXwzktZUrPGtsrpfuHQcAvR6X3tzSRRuXai5dnX6B+1i2eTHKRpvLLp3GLLXdNncwuf3W/bx33LPneD+6U6d+Tm37j3A/il5apuy1ef+yhS7PGuv0uATY4LtENUxLmOWAF+DESiB5kb5sAFC3+D5nenyu5hfStsuX+D3M4XqonuxCZIKCXYhMULALkQkKdiEyQcEuRCZMdTX+8pUreOi/PZS0nTt7lo7rD9L1x+qat+IJ65kNeOuc1VWeXNMnde3aBW/7c/std1DbCxf5qm8/aF/Vm+PHm19M25rGj3XoyH5qu8SnAwVJxgAAVmqw1Q6SRYIV66I1R201+Cp4t5v2sTXLV60vneU17bzkiTBrK3xcs+DnvW9/ug3YcMTv05XltKoVoSe7EJmgYBciExTsQmSCgl2ITFCwC5EJCnYhMmFD6c3MbgfwVxi3ZHYAJ9z9s2b2CQB/AuCVDJaPufs3o33119Zw6vEfJG1Fg7/uNIq0bRRIE/3VdEsdAChJzS8AaDWD+nSttB/dVpDccesRapufS0suALB0iUuR3SDhwofpOVkF19Das3zuZ2p+bhb0J2q1Se23KBFmL5cAW0GSzLUV3h140E/Ltr1Z7sfiYZ40tPziVWrzUCrj8793f7rh6R4iyQHA8mo6wceD/k+b0dlLAH/u7t83s3kAj5nZtye2z7j7f9jEPoQQu8xmer2dAXBm8vOymT0N4PBOOyaE2F5u6DO7mR0F8DYAj042fcTMnjCzB8yM18oVQuw6mw52M5sD8DUAH3X3awA+B+AOAHdh/OT/FBl33MxOmtnJ9XX+OVoIsbNsKtjNrIVxoH/R3R8CAHc/5+6Vu9cAPg/g7tRYdz/h7sfc/Vivx7/TLYTYWTYMdhu3mPgCgKfd/dPXbT903Z+9D8Cp7XdPCLFdbGY1/rcBfAjAk2b2+GTbxwB80MzuwliOOw3gTzfakdc1yvW0ZDAYcjlpRGxR1luXtP0BgN4Mf41rceUNRZWWVkbknABgeY3bhkH23Qw34eoFXpvscjs9sHsrf1fVneVz1eHqGtbBJczK03PsgTbUaHA/mkG2HBo8g61PfByO+EfKTof72JvrUlt9ld+Po1FaAgSAlZV0hmN7ZoaOmZ1PZwg2Cn4Db2Y1/rsAUmcfaupCiNcX+gadEJmgYBciExTsQmSCgl2ITFCwC5EJUy04WZYlli5eTBudyxYdkik1E2RQddpcPimM61rlOi8aOLiWtq1f48Uh15b5/lqBzrd/P//2cd3lkszF1bQs17/KNbSucVtnxK9LyU0A0vtcq7kU+Yv+L6ittz+4Ls5ltEE/fa1txM85qCmJVsWNHkipMH6t10mhyooripidS0tvUfaonuxCZIKCXYhMULALkQkKdiEyQcEuRCYo2IXIhKlKb2ZAo5WWxNpFkHlFXpKKkmcSDa5wOWY44H2y1q9yGW1I+mvZkPdRawZZXjP7eEHBghTZBIBWj8/VnKebrM12eNZbdZ7LWljj89gk8hoA1K20blQZn4+LxmW51i1L1NYNet91SAFRq3j22jAoVrp+LciW63OtrFvw865JH77VUSDbzqalN6+5D3qyC5EJCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhOmKr0VZphppA/pI15wsk+KNq4H/bOGQfaal/xYqIJULpIOVQTZSYESgiKSSYKUJwP3cZZkAlqfn3N5NZDXSu5HGWSA1UXaxnrAjQn2N+SSaN3l2WY1KWJpQbFSHwS99Fa4zFoGSW+jgo9zS8dEf8il5T5JOayCa6InuxCZoGAXIhMU7EJkgoJdiExQsAuRCRuuxptZF8B3AHQmf//X7v5xM3sTgC8DuAXAYwA+5O7BMjdQjUZYPnc+aVtf5quto9X0yno95O2HghJ0mCHJEQBQNPmUDMkqeG18xTpaHfWg5VUddLy1IqjXR87t2lWuXDSCFfdmoAo0giJ0rF2TBYlBNgrmcTVYZW7y+2BYpucx6PKFVtBCySruf1XyFfdBcD+yR24ZqDXDYTopK2qJtpkn+wDA77n7b2DcnvkeM3sHgL8A8Bl3fwuAywA+vIl9CSF2iQ2D3ce88mhtTf45gN8D8NeT7Q8CeO+OeCiE2BY225+9Mengeh7AtwH8FMAVd3/lfctLAA7vjItCiO1gU8Hu7pW73wXgCIC7AfzqZg9gZsfN7KSZnRwMg68YCSF2lBtajXf3KwD+BsBvAdhr9v++53cEwMtkzAl3P+buxzrhVyWFEDvJhsFuZrea2d7Jzz0AfwDgaYyD/p9P/uw+AN/YKSeFEFtnM4kwhwA8aGYNjF8cvuru/93MngLwZTP7dwB+AOALG+1oNBzizOkXkzYLZIsOqd/VqIO2RS3+LsIH/FjDoIVP3Uz7UQX1xcqgrVUVJORYcG6jQLJr9tL12IqKv66XwXx4IB2aB1k+TvYZyHyNYH91zf23mt/GXqf9qANZy4PrGeTqIJgqDIgfAGCN9PE8eBbTWnPBJdkw2N39CQBvS2x/HuPP70KIvwfoG3RCZIKCXYhMULALkQkKdiEyQcEuRCaYR/LJdh/M7AKAV7S3RQAXp3Zwjvx4NfLj1fx98+MfuvutKcNUg/1VBzY76e7HduXg8kN+ZOiH3sYLkQkKdiEyYTeD/cQuHvt65MerkR+v5g3jx659ZhdCTBe9jRciE3Yl2M3sHjP7sZk9Z2b374YPEz9Om9mTZva4mZ2c4nEfMLPzZnbqum37zezbZvaTyf/7dsmPT5jZy5M5edzM3jMFP243s78xs6fM7Edm9i8n26c6J4EfU50TM+ua2d+Z2Q8nfvzbyfY3mdmjk7j5ipmle30x3H2q/zAu7PlTAG8G0AbwQwB3TtuPiS+nASzuwnF/B8DbAZy6btu/B3D/5Of7AfzFLvnxCQD/asrzcQjA2yc/zwN4FsCd056TwI+pzgkAAzA3+bkF4FEA7wDwVQAfmGz/jwD+xY3sdzee7HcDeM7dn/dx6ekvA7h3F/zYNdz9OwCWXrP5XowLdwJTKuBJ/Jg67n7G3b8/+XkZ4+IohzHlOQn8mCo+ZtuLvO5GsB8G8PPrft/NYpUO4Ftm9piZHd8lH17hgLufmfx8FsCBXfTlI2b2xORt/o5/nLgeMzuKcf2ER7GLc/IaP4Apz8lOFHnNfYHune7+dgD/DMCfmdnv7LZDwPiVHWHNkR3lcwDuwLhHwBkAn5rWgc1sDsDXAHzU3V/V1WKac5LwY+pz4lso8srYjWB/GcDt1/1Oi1XuNO7+8uT/8wC+jt2tvHPOzA4BwOT/dOucHcbdz01utBrA5zGlOTGzFsYB9kV3f2iyeepzkvJjt+ZkcuwbLvLK2I1g/x6At05WFtsAPgDg4Wk7YWazZjb/ys8A/hDAqXjUjvIwxoU7gV0s4PlKcE14H6YwJ2ZmGNcwfNrdP32daapzwvyY9pzsWJHXaa0wvma18T0Yr3T+FMC/3iUf3oyxEvBDAD+aph8AvoTx28ERxp+9Poxxz7xHAPwEwP8CsH+X/PjPAJ4E8ATGwXZoCn68E+O36E8AeHzy7z3TnpPAj6nOCYB/hHER1ycwfmH5N9fds38H4DkA/xVA50b2q2/QCZEJuS/QCZENCnYhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkgoJdiEz4vyDkf3vWDSAhAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "x_train_ = x_train.astype('float32') / 255.\n",
        "x_test_ = x_test.astype('float32') / 255.\n",
        "\n",
        "\n",
        "x_train_ = x_train_.reshape(-1, w_dim * h_dim * c_dim)\n",
        "x_test_ = x_test_.reshape(-1, w_dim * h_dim * c_dim)"
      ],
      "metadata": {
        "id": "Xg9FUo7UW4IU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5sx-T2HsTDF",
        "outputId": "31f03cd1-2d6d-4d1d-efe4-867223cdfa85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.23137255, 0.24313726, 0.24705882, ..., 0.48235294, 0.36078432,\n",
              "       0.28235295], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCZHqM1Z3bQ4",
        "outputId": "4a3e4013-0d06-4270-a78f-89b82cdc1f9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx8WfXpn3qQk",
        "outputId": "f300ea60-b8c9-4315-c2c3-ef6ced6969fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MywUPlKzJM37"
      },
      "source": [
        "## Определение Encoder / decoder "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikty0N9NJM38"
      },
      "source": [
        "**Задание 2**  Ниже приведен код, который  определяет энкодер и декодер, и реализуйт выборку с приемом репараметризации в предоставленном пространстве."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_batch_size = 100\n",
        "batch_size = master_batch_size\n",
        "original_dim = x_train_.shape[1] # Number of pixels in  images.\n",
        "latent_dim = 10 # d, dimensionality of the latent code t.\n",
        "intermediate_dim = 256 # Size of the hidden layer.\n",
        "epochs = 50\n",
        "\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "\n",
        "\n",
        "def create_encoder(input_dim):\n",
        "    # Encoder network.\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    encoder = Sequential(name='encoder')\n",
        "    encoder.add(InputLayer([input_dim], name = 'Inpute_encoder'))\n",
        "   # encoder.add(BatchNormalization())\n",
        "    encoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoder'))\n",
        "    # encoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_encoder'))\n",
        "    # encoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_encoder'))\n",
        "    encoder.add(Dense(2 * latent_dim, kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return encoder\n",
        "\n",
        "    \n",
        "encoder = create_encoder(original_dim)\n",
        "\n",
        "get_t_mean = Lambda(lambda h: h[:, :latent_dim])\n",
        "get_t_log_var = Lambda(lambda h: h[:, latent_dim:])\n",
        "\n",
        "\n",
        "get_x_mean = Lambda(lambda h: h[:, :original_dim])\n",
        "get_x_var = Lambda(lambda h: h[:, original_dim:])\n",
        "\n",
        "\n",
        "h = encoder(x)\n",
        "t_mean = get_t_mean(h)\n",
        "t_log_var = get_t_log_var(h)\n",
        "\n",
        "# Sampling from the distribution \n",
        "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
        "# with reparametrization trick.\n",
        "def sampling(args):\n",
        "    \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
        "    \n",
        "    The sample should be computed with reparametrization trick.\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
        "        args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
        "    \"\"\"\n",
        "    t_mean, t_log_var = args\n",
        "    t_std = tf.exp(0.5*t_log_var)\n",
        "    #print(t_std)\n",
        "    eps = tf.random.normal(t_mean.shape, mean=0, stddev=1, dtype=tf.float32)*t_std + t_mean\n",
        "    return eps\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "t = Lambda(sampling)([t_mean, t_log_var])\n",
        "\n",
        "def create_decoder(input_dim):\n",
        "    # Decoder network\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    decoder = Sequential(name='decoder')\n",
        "    decoder.add(InputLayer([input_dim], name = 'Inpute_decoder'))\n",
        "    # decoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_decoder'))\n",
        "    # decoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_decodder'))\n",
        "    decoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoider'))\n",
        "    decoder.add(Dense(2*original_dim, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return decoder\n",
        "\n",
        "    \n",
        "decoder = create_decoder(latent_dim)\n",
        "x_decoded = decoder(t)\n",
        "x_decoded_mean = get_x_mean(x_decoded)\n",
        "x_decoded_var = get_x_var(x_decoded)\n"
      ],
      "metadata": {
        "id": "91jicC-t9wag"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vlb_binomial(x, x_decoded_mean,  x_decoded_var, t_mean, t_log_var):\n",
        "    \"\"\"Returns the value of negative Variational Lower Bound\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        x: (batch_size x number_of_pixels) matrix with one image per row with zeros and ones\n",
        "        x_decoded_mean: (batch_size x number_of_pixels) mean of the distribution p(x | t), real numbers from 0 to 1\n",
        "        t_mean: (batch_size x latent_dim) mean vector of the (normal) distribution q(t | x)\n",
        "        t_log_var: (batch_size x latent_dim) logarithm of the variance vector of the (normal) distribution q(t | x)\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor with one element (averaged across the batch), VLB\n",
        "    \"\"\"\n",
        "\n",
        "    #cce = tf.keras.losses.CategoricalCrossentropy(axis=1)\n",
        "    t_var =  tf.exp(t_log_var)\n",
        "    kl = -t_log_var/2.0 + (t_var + t_mean**2 - 1)/2.0\n",
        "    kl = tf.reduce_sum(kl, axis=1)\n",
        "    batch_size = x.shape[0]\n",
        "    number_of_pixels = x.shape[1]\n",
        "    latend_dim = t_mean.shape[1]\n",
        "\n",
        "    two_pi = tf.constant(2.0 * np.pi)      \n",
        "    #log_p = tf.keras.losses.binary_crossentropy(x, x_decoded_mean)                                                                                                                        \n",
        "    #log_p = -number_of_pixels/ 2.0 * tf.math.log(two_pi * tf.math.pow(x_decoded_var, 2.0) + 1e-6) -  tf.math.reduce_euclidean_norm(x_decoded_mean - x, axis=0) / (2.0 * tf.math.pow(x_decoded_var, 2.0)  + 1.0 * 1e-6)\n",
        "    log_p = -0.5 * (tf.math.log(two_pi) + tf.math.log(x_decoded_var + 1e-6) + tf.math.log(x_decoded_var + 1e-6) +  tf.math.divide_no_nan(tf.math.pow(tf.math.reduce_euclidean_norm(x_decoded_mean - x, axis=0), 2.0) , tf.math.pow(x_decoded_var, 2.0)) + 1.0 * 1e-6)\n",
        "    log_p = tf.reduce_sum(log_p, axis=1) \n",
        "\n",
        "    #result = tf.reduce_mean(number_of_pixels*log_p - kl) \n",
        "    result = tf.reduce_mean(log_p - kl) #* (x_train_.shape[0] / master_batch_size )\n",
        "    \n",
        "    print(\"batch_size = {}, number_of_pixels = {} kl_size = {}\".format(batch_size, number_of_pixels, kl.shape))\n",
        "    return tf.math.multiply_no_nan(result, tf.constant([-1.0]))"
      ],
      "metadata": {
        "id": "tJDDX4vY-Agp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RomMQ_HJUWa"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OORaYf9xJUWf"
      },
      "source": [
        "**Задание 3** Запустите указанные ниже ячейки, чтобы обучить модель с настройками по умолчанию. Измените параметры, чтобы получить лучшие результаты. Особенно обратите внимание на архитектуру кодировщика/декодера (например, использование большего количества слоев, возможно, сделав их сверточными), скорость обучения и количество эпох."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = vlb_binomial(x, x_decoded_mean, x_decoded_var, t_mean, t_log_var)\n",
        "vae = Model(x, x_decoded_mean)\n",
        "tf.keras.utils.plot_model(vae,show_shapes = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "4LsUPwqJ-DHv",
        "outputId": "bd31d1da-7b51-45e8-fce3-81e1e1790132"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size = 100, number_of_pixels = 3072 kl_size = (100,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hist = cvae.fit(x=[x_train_, y_train],\n",
        "#                 y=[x_train_, y_train],\n",
        "#                 shuffle=True,\n",
        "#                 epochs=epochs,\n",
        "#                 batch_size=batch_size,\n",
        "#                 validation_data=([x_test_, y_test], [x_test_,  y_test]),\n",
        "#                 verbose=2)\n",
        "\n",
        "# Keras will provide input (x) and output (x_decoded_mean) to the function that\n",
        "# should construct loss, but since our function also depends on other\n",
        "# things (e.g. t_means), it is easier to build the loss in advance and pass\n",
        "# a function that always returns it.\n",
        "vae.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss=lambda x, y: loss)\n",
        "#vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\\\n",
        "#                amsgrad=False, name='Adam'), loss=lambda x, y: loss)\n",
        "\n",
        "save_filepath = '/tmp_cifar/checkpoint'\n",
        "\n",
        "hist = vae.fit(x=[x_train_, y_train],\n",
        "                y=x_train_,\n",
        "                shuffle=True,\n",
        "                epochs=20,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=([x_test_, y_test], x_test_), verbose=1, callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', mode = \"min\", verbose = 1, patience = 5)\n",
        "                                                                                      , tf.keras.callbacks.ModelCheckpoint(filepath = save_filepath, monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only=True)])\n",
        "\n",
        "vae.load_weights(save_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVeiGBzi-GvW",
        "outputId": "36952791-3f13-4b75-ec4e-bea0e8738f27"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48800/50000 [============================>.] - ETA: 0s - loss: 9175.8925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 7394.65897, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 8s 161us/sample - loss: 9138.5556 - val_loss: 7394.6590\n",
            "Epoch 2/20\n",
            "49700/50000 [============================>.] - ETA: 0s - loss: 6995.3296\n",
            "Epoch 2: val_loss improved from 7394.65897 to 6783.58581, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 79us/sample - loss: 6992.2467 - val_loss: 6783.5858\n",
            "Epoch 3/20\n",
            "49500/50000 [============================>.] - ETA: 0s - loss: 6601.7478\n",
            "Epoch 3: val_loss improved from 6783.58581 to 6479.86797, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 75us/sample - loss: 6600.9549 - val_loss: 6479.8680\n",
            "Epoch 4/20\n",
            "48800/50000 [============================>.] - ETA: 0s - loss: 6477.0516\n",
            "Epoch 4: val_loss did not improve from 6479.86797\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6477.9213 - val_loss: 6535.7659\n",
            "Epoch 5/20\n",
            "49100/50000 [============================>.] - ETA: 0s - loss: 6407.2773\n",
            "Epoch 5: val_loss improved from 6479.86797 to 6338.56154, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 73us/sample - loss: 6404.1405 - val_loss: 6338.5615\n",
            "Epoch 6/20\n",
            "48900/50000 [============================>.] - ETA: 0s - loss: 6356.7699\n",
            "Epoch 6: val_loss improved from 6338.56154 to 6259.68657, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 78us/sample - loss: 6356.1133 - val_loss: 6259.6866\n",
            "Epoch 7/20\n",
            "49300/50000 [============================>.] - ETA: 0s - loss: 6321.3317\n",
            "Epoch 7: val_loss did not improve from 6259.68657\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 6320.5888 - val_loss: 6400.2171\n",
            "Epoch 8/20\n",
            "49400/50000 [============================>.] - ETA: 0s - loss: 6289.6757\n",
            "Epoch 8: val_loss did not improve from 6259.68657\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6288.6512 - val_loss: 6453.3551\n",
            "Epoch 9/20\n",
            "49400/50000 [============================>.] - ETA: 0s - loss: 6267.5945\n",
            "Epoch 9: val_loss improved from 6259.68657 to 6248.43389, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 75us/sample - loss: 6267.4632 - val_loss: 6248.4339\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - ETA: 0s - loss: 6247.6166\n",
            "Epoch 10: val_loss did not improve from 6248.43389\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6247.6166 - val_loss: 6253.7819\n",
            "Epoch 11/20\n",
            "48900/50000 [============================>.] - ETA: 0s - loss: 6230.2398\n",
            "Epoch 11: val_loss improved from 6248.43389 to 6185.24532, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 74us/sample - loss: 6229.4463 - val_loss: 6185.2453\n",
            "Epoch 12/20\n",
            "49400/50000 [============================>.] - ETA: 0s - loss: 6216.3188\n",
            "Epoch 12: val_loss did not improve from 6185.24532\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6215.3233 - val_loss: 6269.9732\n",
            "Epoch 13/20\n",
            "49500/50000 [============================>.] - ETA: 0s - loss: 6206.0530\n",
            "Epoch 13: val_loss improved from 6185.24532 to 6132.81196, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 78us/sample - loss: 6205.2673 - val_loss: 6132.8120\n",
            "Epoch 14/20\n",
            "49600/50000 [============================>.] - ETA: 0s - loss: 6193.6466\n",
            "Epoch 14: val_loss did not improve from 6132.81196\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 6193.6108 - val_loss: 6181.9137\n",
            "Epoch 15/20\n",
            "49400/50000 [============================>.] - ETA: 0s - loss: 6184.4515\n",
            "Epoch 15: val_loss did not improve from 6132.81196\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6186.0908 - val_loss: 6274.2319\n",
            "Epoch 16/20\n",
            "49400/50000 [============================>.] - ETA: 0s - loss: 6175.8229\n",
            "Epoch 16: val_loss did not improve from 6132.81196\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6175.6638 - val_loss: 6190.9872\n",
            "Epoch 17/20\n",
            "49300/50000 [============================>.] - ETA: 0s - loss: 6169.0349\n",
            "Epoch 17: val_loss did not improve from 6132.81196\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6167.7516 - val_loss: 6288.4948\n",
            "Epoch 18/20\n",
            "49300/50000 [============================>.] - ETA: 0s - loss: 6160.6702\n",
            "Epoch 18: val_loss did not improve from 6132.81196\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 6162.0860 - val_loss: 6171.4324\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - ETA: 0s - loss: 6156.0086\n",
            "Epoch 19: val_loss did not improve from 6132.81196\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6156.0086 - val_loss: 6144.2657\n",
            "Epoch 20/20\n",
            "49100/50000 [============================>.] - ETA: 0s - loss: 6150.7482\n",
            "Epoch 20: val_loss did not improve from 6132.81196\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 6149.8418 - val_loss: 6261.2619\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f523c37fc50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "del vae\n",
        "\n",
        "# Start tf session so we can run code.\n",
        "#sess = tf.InteractiveSession()\n",
        "sess=tf.compat.v1.InteractiveSession()\n",
        "# Connect keras to the created session.\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "7mZx66FMshSc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = master_batch_size\n",
        "original_dim = x_train_.shape[1] # Number of pixels in  images.\n",
        "latent_dim = 10 # d, dimensionality of the latent code t.\n",
        "intermediate_dim = 256 # Size of the hidden layer.\n",
        "epochs = 50\n",
        "\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "\n",
        "\n",
        "def create_encoder(input_dim):\n",
        "    # Encoder network.\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    encoder = Sequential(name='encoder')\n",
        "    encoder.add(InputLayer([input_dim], name = 'Inpute_encoder'))\n",
        "   # encoder.add(BatchNormalization())\n",
        "    encoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoder'))\n",
        "    # encoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_encoder'))\n",
        "    # encoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_encoder'))\n",
        "    encoder.add(Dense(2 * latent_dim, kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return encoder\n",
        "\n",
        "    \n",
        "encoder = create_encoder(original_dim)\n",
        "\n",
        "get_t_mean = Lambda(lambda h: h[:, :latent_dim])\n",
        "get_t_log_var = Lambda(lambda h: h[:, latent_dim:])\n",
        "\n",
        "\n",
        "get_x_mean = Lambda(lambda h: h[:, :original_dim])\n",
        "get_x_var = Lambda(lambda h: h[:, original_dim:])\n",
        "\n",
        "\n",
        "h = encoder(x)\n",
        "t_mean = get_t_mean(h)\n",
        "t_log_var = get_t_log_var(h)\n",
        "\n",
        "# Sampling from the distribution \n",
        "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
        "# with reparametrization trick.\n",
        "def sampling(args):\n",
        "    \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
        "    \n",
        "    The sample should be computed with reparametrization trick.\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
        "        args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
        "    \"\"\"\n",
        "    t_mean, t_log_var = args\n",
        "    t_std = tf.exp(0.5*t_log_var)\n",
        "    #print(t_std)\n",
        "    eps = tf.random.normal(t_mean.shape, mean=0, stddev=1, dtype=tf.float32)*t_std + t_mean\n",
        "    return eps\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "t = Lambda(sampling)([t_mean, t_log_var])\n",
        "\n",
        "def create_decoder(input_dim):\n",
        "    # Decoder network\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    decoder = Sequential(name='decoder')\n",
        "    decoder.add(InputLayer([input_dim], name = 'Inpute_decoder'))\n",
        "    # decoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_decoder'))\n",
        "    # decoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_decodder'))\n",
        "    decoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoider'))\n",
        "    decoder.add(Dense(2*original_dim, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return decoder\n",
        "\n",
        "    \n",
        "decoder = create_decoder(latent_dim)\n",
        "x_decoded = decoder(t)\n",
        "x_decoded_mean = get_x_mean(x_decoded)\n",
        "x_decoded_var = get_x_var(x_decoded)\n"
      ],
      "metadata": {
        "id": "IJ_Dau_SsKCf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "loss = vlb_binomial(x, x_decoded_mean, x_decoded_var, t_mean, t_log_var)\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\\\n",
        "                amsgrad=False, name='Adam'), loss=lambda x, y: loss)\n",
        "\n",
        "save_filepath = '/tmp_cifar/checkpoint'\n",
        "vae.load_weights(save_filepath)\n",
        "hist2 = vae.fit(x=[x_train_, y_train],\n",
        "                y=x_train_,\n",
        "                shuffle=True,\n",
        "                epochs=30,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=([x_test_, y_test], x_test_), verbose=1, callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', mode = \"min\", verbose = 1, patience = 5)\n",
        "                                                                                      , tf.keras.callbacks.ModelCheckpoint(filepath = save_filepath, monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only=True)])\n",
        "vae.load_weights(save_filepath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXJnUy4eRRz6",
        "outputId": "0d5d2e83-204e-4461-beaa-7bb7a3a10486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size = 100, number_of_pixels = 3072 kl_size = (100,)\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "49900/50000 [============================>.] - ETA: 0s - loss: 6167.7044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 6092.85917, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 77us/sample - loss: 6167.1071 - val_loss: 6092.8592\n",
            "Epoch 2/30\n",
            "48700/50000 [============================>.] - ETA: 0s - loss: 6069.2864\n",
            "Epoch 2: val_loss improved from 6092.85917 to 6076.39586, saving model to /tmp_cifar/checkpoint\n",
            "INFO:tensorflow:Assets written to: /tmp_cifar/checkpoint/assets\n",
            "50000/50000 [==============================] - 4s 71us/sample - loss: 6066.4890 - val_loss: 6076.3959\n",
            "Epoch 3/30\n",
            "49400/50000 [============================>.] - ETA: 0s - loss: 6053.7219\n",
            "Epoch 3: val_loss improved from 6076.39586 to 6075.10499, saving model to /tmp_cifar/checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Визуализация реконструкции для обучения и проверки данных\n",
        "На рисунке ниже вы можете увидеть способность вашей сети к реконструкции на основе данных обучения и валидации. В каждом из двух изображений левый столбец — это изображения CIFAR, а правый столбец — это соответствующее изображение после прохождения через автоэнкодер (или, точнее, среднее значение биномиального распределения по выходным изображениям).\n",
        "\n",
        "Обратите внимание, что получение наилучшей возможной реконструкции не является целью VAE, дивергенция Кульбака-Лейблера KL функции потерь ухудшает производительность реконструкции. Но реконструкция в любом случае должна быть разумной, и они предоставляют визуальный инструмент отладки кода."
      ],
      "metadata": {
        "id": "Qp3XzlDOJhBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_decoded_mean = vae.get_layer('decoder')\n"
      ],
      "metadata": {
        "id": "7bYrpivkLDlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for fid_idx, (data, title) in enumerate(zip([x_train_, x_test_]\n",
        "                                          , ['Train', 'Validation'])\n",
        "                                        ):\n",
        "    n = 10 \n",
        "    fig, ax = plt.subplots(n, 2, figsize=(10, 4 * n))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    ind = 0\n",
        "    decoded = sess.run(get_x_mean(x_decoded), feed_dict={x: data[:batch_size, :]})\n",
        "    for i in range(n):\n",
        "        ax[i][0].imshow(data[i, :].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][1].imshow(decoded[i, :original_dim].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][0].set_title('Input')\n",
        "        ax[i][1].set_title('Mean Decode')\n",
        "        ax[i][0].axis('off')\n",
        "        ax[i][1].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lOzBs2xm-enF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (15, 10))\n",
        "\n",
        "\n",
        "train_loss = np.concatenate([hist.history['loss'], hist2.history['loss']])\n",
        "\n",
        "plt.plot(train_loss, label = 'Train Loss')\n",
        "\n",
        "\n",
        "test_loss = np.concatenate([hist.history['val_loss'], hist2.history['val_loss']])\n",
        "\n",
        "plt.plot(test_loss, label = 'Test Loss')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "1bIqv3NQ-jcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A2AgmDNqKMf"
      },
      "source": [
        "## Варьирование параметров модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl_p9-yVqKMi"
      },
      "source": [
        "Проварьируем структуру модели, добавив промежуточных слоев энкодера и декода, естественно прежде увеличив размерность параметров."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "\n",
        "# Start tf session so we can run code.\n",
        "#sess = tf.InteractiveSession()\n",
        "sess=tf.compat.v1.InteractiveSession()\n",
        "# Connect keras to the created session.\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "y_wyep7DqKMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = master_batch_size\n",
        "original_dim = x_train_.shape[1] # Number of pixels in  images.\n",
        "latent_dim = 10 # d, dimensionality of the latent code t.\n",
        "intermediate_dim = 1024 # Size of the hidden layer.\n",
        "epochs = 50\n",
        "\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "\n",
        "\n",
        "def create_encoder(input_dim):\n",
        "    # Encoder network.\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    encoder = Sequential(name='encoder')\n",
        "    encoder.add(InputLayer([input_dim], name = 'Inpute_encoder'))\n",
        "    encoder.add(BatchNormalization())\n",
        "    encoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoder'))\n",
        "    encoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_encoder')) #ADDITION LAYER\n",
        "    encoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_encoder')) #ADDITION LAYER\n",
        "    encoder.add(Dense(2 * latent_dim, kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return encoder\n",
        "\n",
        "    \n",
        "encoder = create_encoder(original_dim)\n",
        "\n",
        "get_t_mean = Lambda(lambda h: h[:, :latent_dim])\n",
        "get_t_log_var = Lambda(lambda h: h[:, latent_dim:])\n",
        "\n",
        "\n",
        "get_x_mean = Lambda(lambda h: h[:, :original_dim])\n",
        "get_x_var = Lambda(lambda h: h[:, original_dim:])\n",
        "\n",
        "\n",
        "h = encoder(x)\n",
        "t_mean = get_t_mean(h)\n",
        "t_log_var = get_t_log_var(h)\n",
        "\n",
        "# Sampling from the distribution \n",
        "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
        "# with reparametrization trick.\n",
        "def sampling(args):\n",
        "    \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
        "    \n",
        "    The sample should be computed with reparametrization trick.\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
        "        args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
        "    \"\"\"\n",
        "    t_mean, t_log_var = args\n",
        "    t_std = tf.exp(0.5*t_log_var)\n",
        "    #print(t_std)\n",
        "    eps = tf.random.normal(t_mean.shape, mean=0, stddev=1, dtype=tf.float32)*t_std + t_mean\n",
        "    return eps\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "t = Lambda(sampling)([t_mean, t_log_var])\n",
        "\n",
        "def create_decoder(input_dim):\n",
        "    # Decoder network\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    decoder = Sequential(name='decoder')\n",
        "    decoder.add(InputLayer([input_dim], name = 'Inpute_decoder'))\n",
        "    decoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_decoder')) #ADDITION LAYER\n",
        "    decoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_decodder')) #ADDITION LAYER\n",
        "    decoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoider'))\n",
        "    decoder.add(Dense(2*original_dim, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return decoder\n",
        "\n",
        "    \n",
        "decoder = create_decoder(latent_dim)\n",
        "x_decoded = decoder(t)\n",
        "x_decoded_mean = get_x_mean(x_decoded)\n",
        "x_decoded_var = get_x_var(x_decoded)\n"
      ],
      "metadata": {
        "id": "Sjf1XgjnqKMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = vlb_binomial(x, x_decoded_mean, x_decoded_var, t_mean, t_log_var)\n",
        "vae = Model(x, x_decoded_mean)\n",
        "tf.keras.utils.plot_model(vae,show_shapes = True,  \n",
        "    show_dtype=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir='LR',\n",
        "    expand_nested=True,\n",
        "    dpi=96,\n",
        "\n",
        "    show_layer_activations=True\n",
        ")"
      ],
      "metadata": {
        "id": "KyC8RwgYsPf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\\\n",
        "                amsgrad=False, name='Adam'), loss=lambda x, y: loss)\n",
        "\n",
        "save_filepath = '/tmp_cifar/checkpoint'\n",
        "\n",
        "hist3 = vae.fit(x=[x_train_, y_train],\n",
        "                y=x_train_,\n",
        "                shuffle=True,\n",
        "                epochs=50,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=([x_test_, y_test], x_test_), verbose=1, callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', mode = \"min\", verbose = 1, patience = 5)\n",
        "                                                                                      , tf.keras.callbacks.ModelCheckpoint(filepath = save_filepath, monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only=True)])\n",
        "vae.load_weights(save_filepath)\n"
      ],
      "metadata": {
        "id": "pUA7LqvcqKMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Визуализация реконструкции для обучения и проверки данных\n",
        "На рисунке ниже вы можете увидеть способность вашей сети к реконструкции на основе данных обучения и валидации. В каждом из двух изображений левый столбец — это изображения CIFAR, а правый столбец — это соответствующее изображение после прохождения через автоэнкодер (или, точнее, среднее значение биномиального распределения по выходным изображениям).\n",
        "\n",
        "Обратите внимание, что получение наилучшей возможной реконструкции не является целью VAE, дивергенция Кульбака-Лейблера KL функции потерь ухудшает производительность реконструкции. Но реконструкция в любом случае должна быть разумной, и они предоставляют визуальный инструмент отладки кода."
      ],
      "metadata": {
        "id": "5hCPDc57qKMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_decoded_mean = vae.get_layer('decoder')\n"
      ],
      "metadata": {
        "id": "7_EnXxyjqKMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for fid_idx, (data, title) in enumerate(zip([x_train_, x_test_]\n",
        "                                          , ['Train', 'Validation'])\n",
        "                                        ):\n",
        "    n = 10 \n",
        "    fig, ax = plt.subplots(n, 2, figsize=(10, 4 * n))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    ind = 0\n",
        "    decoded = sess.run(get_x_mean(x_decoded), feed_dict={x: data[:batch_size, :]})\n",
        "    for i in range(n):\n",
        "        ax[i][0].imshow(data[i, :].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][1].imshow(decoded[i, :original_dim].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][0].set_title('Input')\n",
        "        ax[i][1].set_title('Mean Decode')\n",
        "        ax[i][0].axis('off')\n",
        "        ax[i][1].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E9KNfySwqKMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (15, 10))\n",
        "\n",
        "\n",
        "train_loss = hist3.history['loss']\n",
        "\n",
        "plt.plot(train_loss, label = 'Train Loss')\n",
        "\n",
        "\n",
        "test_loss = hist3.history['val_loss']\n",
        "\n",
        "plt.plot(test_loss, label = 'Test Loss')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "DO5IstDDqKMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Добавим регулерезацию \n",
        "\n",
        "Как видно по графику ошибки, параметров стало достаточно для переобучения.\n",
        "\n",
        "Однако, субъективное восприятие качества изображений говорит о том, что добавление слоев пошло на пользу.\n",
        "\n",
        "Для борьбы с переобучением добавим DropOut"
      ],
      "metadata": {
        "id": "5-zRD4AtvZaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "del vae\n",
        "# Start tf session so we can run code.\n",
        "#sess = tf.InteractiveSession()\n",
        "sess=tf.compat.v1.InteractiveSession()\n",
        "# Connect keras to the created session.\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "PCkfull6wyvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = master_batch_size\n",
        "original_dim = x_train_.shape[1] # Number of pixels in  images.\n",
        "latent_dim = 10 # d, dimensionality of the latent code t.\n",
        "intermediate_dim = 1024 # Size of the hidden layer.\n",
        "epochs = 50\n",
        "\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "\n",
        "\n",
        "def create_encoder(input_dim):\n",
        "    # Encoder network.\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    encoder = Sequential(name='encoder')\n",
        "    encoder.add(InputLayer([input_dim], name = 'Inpute_encoder'))\n",
        "    encoder.add(BatchNormalization())\n",
        "    encoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoder'))\n",
        "    encoder.add(Dropout(0.25))\n",
        "    encoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_encoder')) #ADDITION LAYER\n",
        "    encoder.add(Dropout(0.25))\n",
        "    encoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_encoder')) #ADDITION LAYER\n",
        "    encoder.add(Dense(2 * latent_dim, kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return encoder\n",
        "\n",
        "    \n",
        "encoder = create_encoder(original_dim)\n",
        "\n",
        "get_t_mean = Lambda(lambda h: h[:, :latent_dim])\n",
        "get_t_log_var = Lambda(lambda h: h[:, latent_dim:])\n",
        "\n",
        "\n",
        "get_x_mean = Lambda(lambda h: h[:, :original_dim])\n",
        "get_x_var = Lambda(lambda h: h[:, original_dim:])\n",
        "\n",
        "\n",
        "h = encoder(x)\n",
        "t_mean = get_t_mean(h)\n",
        "t_log_var = get_t_log_var(h)\n",
        "\n",
        "# Sampling from the distribution \n",
        "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
        "# with reparametrization trick.\n",
        "def sampling(args):\n",
        "    \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
        "    \n",
        "    The sample should be computed with reparametrization trick.\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
        "        args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
        "    \"\"\"\n",
        "    t_mean, t_log_var = args\n",
        "    t_std = tf.exp(0.5*t_log_var)\n",
        "    #print(t_std)\n",
        "    eps = tf.random.normal(t_mean.shape, mean=0, stddev=1, dtype=tf.float32)*t_std + t_mean\n",
        "    return eps\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "t = Lambda(sampling)([t_mean, t_log_var])\n",
        "\n",
        "def create_decoder(input_dim):\n",
        "    # Decoder network\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    decoder = Sequential(name='decoder')\n",
        "    decoder.add(InputLayer([input_dim], name = 'Inpute_decoder'))\n",
        "    decoder.add(Dropout(0.25))\n",
        "    decoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_decoder')) #ADDITION LAYER\n",
        "    decoder.add(Dropout(0.25))\n",
        "    decoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_decodder')) #ADDITION LAYER\n",
        "    decoder.add(Dropout(0.25))\n",
        "    decoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoider'))\n",
        "    decoder.add(Dense(2*original_dim, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return decoder\n",
        "\n",
        "    \n",
        "decoder = create_decoder(latent_dim)\n",
        "x_decoded = decoder(t)\n",
        "x_decoded_mean = get_x_mean(x_decoded)\n",
        "x_decoded_var = get_x_var(x_decoded)\n"
      ],
      "metadata": {
        "id": "uXgGhkPCwyvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = vlb_binomial(x, x_decoded_mean, x_decoded_var, t_mean, t_log_var)\n",
        "vae = Model(x, x_decoded_mean)\n",
        "tf.keras.utils.plot_model(vae,show_shapes = True,  \n",
        "    show_dtype=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir='LR',\n",
        "    expand_nested=True,\n",
        "    dpi=96,\n",
        "\n",
        "    show_layer_activations=True\n",
        ")"
      ],
      "metadata": {
        "id": "7YobD8YTwyvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\\\n",
        "                amsgrad=False, name='Adam'), loss=lambda x, y: loss)\n",
        "\n",
        "save_filepath = '/tmp_cifar/checkpoint'\n",
        "\n",
        "hist4 = vae.fit(x=[x_train_, y_train],\n",
        "                y=x_train_,\n",
        "                shuffle=True,\n",
        "                epochs=50,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=([x_test_, y_test], x_test_), verbose=1, callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', mode = \"min\", verbose = 1, patience = 5)\n",
        "                                                                                      , tf.keras.callbacks.ModelCheckpoint(filepath = save_filepath, monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only=True)])\n",
        "vae.load_weights(save_filepath)\n"
      ],
      "metadata": {
        "id": "dV_v01PLwyvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Визуализация реконструкции для обучения и проверки данных\n",
        "На рисунке ниже вы можете увидеть способность вашей сети к реконструкции на основе данных обучения и валидации. В каждом из двух изображений левый столбец — это изображения CIFAR, а правый столбец — это соответствующее изображение после прохождения через автоэнкодер (или, точнее, среднее значение биномиального распределения по выходным изображениям).\n",
        "\n",
        "Обратите внимание, что получение наилучшей возможной реконструкции не является целью VAE, дивергенция Кульбака-Лейблера KL функции потерь ухудшает производительность реконструкции. Но реконструкция в любом случае должна быть разумной, и они предоставляют визуальный инструмент отладки кода."
      ],
      "metadata": {
        "id": "YBGNmJOxwyvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_decoded_mean = vae.get_layer('decoder')\n"
      ],
      "metadata": {
        "id": "RfcYXvlxwyvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for fid_idx, (data, title) in enumerate(zip([x_train_, x_test_]\n",
        "                                          , ['Train', 'Validation'])\n",
        "                                        ):\n",
        "    n = 10 \n",
        "    fig, ax = plt.subplots(n, 2, figsize=(10, 4 * n))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    ind = 0\n",
        "    decoded = sess.run(get_x_mean(x_decoded), feed_dict={x: data[:batch_size, :]})\n",
        "    for i in range(n):\n",
        "        ax[i][0].imshow(data[i, :].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][1].imshow(decoded[i, :original_dim].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][0].set_title('Input')\n",
        "        ax[i][1].set_title('Mean Decode')\n",
        "        ax[i][0].axis('off')\n",
        "        ax[i][1].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZPAvGPgmwyvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (15, 10))\n",
        "\n",
        "\n",
        "train_loss =  hist4.history['loss']\n",
        "\n",
        "plt.plot(train_loss, label = 'Train Loss')\n",
        "\n",
        "\n",
        "test_loss =  hist4.history['val_loss']\n",
        "\n",
        "plt.plot(test_loss, label = 'Test Loss')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "-FH0P0Yrwyvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метод оптимизации\n",
        "\n",
        "Судя по графику функции ошибки, переобучение было пресечено, но из-за роста пространства параметров столкнулись со следующей проблемой - локальный минимум, из-за которого показатели сильно ухудшились.\n",
        "\n",
        "Для борьбы с этим заменим метод оптимизации Adam на AdaBelief, [который имеет наилучшие показатели](https://juntang-zhuang.github.io/adabelief/)  на протяжении обучения.\n",
        "\n",
        "Для исследования поведения алгоритма оптимизации, уберем DropOut"
      ],
      "metadata": {
        "id": "LZjBUThP0xZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "metadata": {
        "id": "f0GX7mEk20AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "pN0-l8Uk23GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "del vae\n",
        "# Start tf session so we can run code.\n",
        "#sess = tf.InteractiveSession()\n",
        "sess=tf.compat.v1.InteractiveSession()\n",
        "# Connect keras to the created session.\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "mhcr65nG12ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = master_batch_size\n",
        "original_dim = x_train_.shape[1] # Number of pixels in  images.\n",
        "latent_dim = 10 # d, dimensionality of the latent code t.\n",
        "intermediate_dim = 1024 # Size of the hidden layer.\n",
        "epochs = 50\n",
        "\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "\n",
        "\n",
        "def create_encoder(input_dim):\n",
        "    # Encoder network.\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    encoder = Sequential(name='encoder')\n",
        "    encoder.add(InputLayer([input_dim], name = 'Inpute_encoder'))\n",
        "    encoder.add(BatchNormalization())\n",
        "   # encoder.add(Dropout(0.25))\n",
        "    encoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoder'))\n",
        "    \n",
        "    encoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_encoder')) #ADDITION LAYER\n",
        "\n",
        "    encoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_encoder')) #ADDITION LAYER\n",
        "   \n",
        "    encoder.add(Dense(2 * latent_dim, kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return encoder\n",
        "\n",
        "    \n",
        "encoder = create_encoder(original_dim)\n",
        "\n",
        "get_t_mean = Lambda(lambda h: h[:, :latent_dim])\n",
        "get_t_log_var = Lambda(lambda h: h[:, latent_dim:])\n",
        "\n",
        "\n",
        "get_x_mean = Lambda(lambda h: h[:, :original_dim])\n",
        "get_x_var = Lambda(lambda h: h[:, original_dim:])\n",
        "\n",
        "\n",
        "h = encoder(x)\n",
        "t_mean = get_t_mean(h)\n",
        "t_log_var = get_t_log_var(h)\n",
        "\n",
        "# Sampling from the distribution \n",
        "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
        "# with reparametrization trick.\n",
        "def sampling(args):\n",
        "    \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
        "    \n",
        "    The sample should be computed with reparametrization trick.\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
        "        args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
        "    \"\"\"\n",
        "    t_mean, t_log_var = args\n",
        "    t_std = tf.exp(0.5*t_log_var)\n",
        "    #print(t_std)\n",
        "    eps = tf.random.normal(t_mean.shape, mean=0, stddev=1, dtype=tf.float32)*t_std + t_mean\n",
        "    return eps\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "t = Lambda(sampling)([t_mean, t_log_var])\n",
        "\n",
        "def create_decoder(input_dim):\n",
        "    # Decoder network\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    decoder = Sequential(name='decoder')\n",
        "    decoder.add(InputLayer([input_dim], name = 'Inpute_decoder'))\n",
        "  \n",
        "    decoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_decoder')) #ADDITION LAYER\n",
        "    decoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_decodder')) #ADDITION LAYER\n",
        "\n",
        "    decoder.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoider'))\n",
        "    #decoder.add(Dropout(0.25))\n",
        "    decoder.add(Dense(2*original_dim, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return decoder\n",
        "\n",
        "    \n",
        "decoder = create_decoder(latent_dim)\n",
        "x_decoded = decoder(t)\n",
        "x_decoded_mean = get_x_mean(x_decoded)\n",
        "x_decoded_var = get_x_var(x_decoded)\n"
      ],
      "metadata": {
        "id": "CMOpKRBN12od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = vlb_binomial(x, x_decoded_mean, x_decoded_var, t_mean, t_log_var)\n",
        "vae = Model(x, x_decoded_mean)\n",
        "tf.keras.utils.plot_model(vae,show_shapes = True,  \n",
        "    show_dtype=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir='LR',\n",
        "    expand_nested=True,\n",
        "    dpi=96,\n",
        "\n",
        "    show_layer_activations=True\n",
        ")"
      ],
      "metadata": {
        "id": "es7mVT_S12og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "vae.compile(optimizer=tfa.optimizers.AdaBelief(learning_rate=0.2e-3), loss=lambda x, y: loss)\n",
        "\n",
        "save_filepath = '/tmp_cifar/checkpoint'\n",
        "\n",
        "hist5 = vae.fit(x=[x_train_, y_train],\n",
        "                y=x_train_,\n",
        "                shuffle=True,\n",
        "                epochs=50,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=([x_test_, y_test], x_test_), verbose=1, callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', mode = \"min\", verbose = 1, patience = 5)\n",
        "                                                                                      , tf.keras.callbacks.ModelCheckpoint(filepath = save_filepath, monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only=True)])\n",
        "vae.load_weights(save_filepath)\n"
      ],
      "metadata": {
        "id": "oA7jQdbG12oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Визуализация реконструкции для обучения и проверки данных\n",
        "На рисунке ниже вы можете увидеть способность вашей сети к реконструкции на основе данных обучения и валидации. В каждом из двух изображений левый столбец — это изображения CIFAR, а правый столбец — это соответствующее изображение после прохождения через автоэнкодер (или, точнее, среднее значение биномиального распределения по выходным изображениям).\n",
        "\n",
        "Обратите внимание, что получение наилучшей возможной реконструкции не является целью VAE, дивергенция Кульбака-Лейблера KL функции потерь ухудшает производительность реконструкции. Но реконструкция в любом случае должна быть разумной, и они предоставляют визуальный инструмент отладки кода."
      ],
      "metadata": {
        "id": "1U-wKAqr12oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_decoded_mean = vae.get_layer('decoder')\n"
      ],
      "metadata": {
        "id": "Nzmg9NoF12ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for fid_idx, (data, title) in enumerate(zip([x_train_, x_test_]\n",
        "                                          , ['Train', 'Validation'])\n",
        "                                        ):\n",
        "    n = 10 \n",
        "    fig, ax = plt.subplots(n, 2, figsize=(10, 4 * n))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    ind = 0\n",
        "    decoded = sess.run(get_x_mean(x_decoded), feed_dict={x: data[:batch_size, :]})\n",
        "    for i in range(n):\n",
        "        ax[i][0].imshow(data[i, :].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][1].imshow(decoded[i, :original_dim].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][0].set_title('Input')\n",
        "        ax[i][1].set_title('Mean Decode')\n",
        "        ax[i][0].axis('off')\n",
        "        ax[i][1].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_u5Z1ji912ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (15, 10))\n",
        "\n",
        "\n",
        "train_loss =  hist5.history['loss']\n",
        "\n",
        "plt.plot(train_loss, label = 'Train Loss')\n",
        "\n",
        "\n",
        "test_loss = hist5.history['val_loss']\n",
        "\n",
        "plt.plot(test_loss, label = 'Test Loss')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "6DFZZOLF12on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ-LHljrINj5"
      },
      "source": [
        "## Создание новых данных\n",
        "**Задание 4** Написать код для создания новых образцов изображений из обученного VAE. Для этого нужно выбрать из априорного распределения $p(t)$, а затем из вероятности $p(x \\mid t)$.\n",
        "\n",
        "**Обратите внимание**, что выборка, которую вы записали в Задаче 2, относится к вариационному распределению $q(t \\mid x)$, а здесь вам нужно взять исходную выборку."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgcaD6a8INj6"
      },
      "outputs": [],
      "source": [
        "n_samples = 10  # To pass automatic grading please use at least 2 samples here.\n",
        "# YOUR CODE HERE.\n",
        "# ...\n",
        "# sampled_im_mean is a tf.Tensor of size 10 x 784 with 10 random\n",
        "# images sampled from the vae model.\n",
        "_mean = tf.zeros([n_samples, original_dim], dtype=tf.float32)\n",
        "_std =tf.ones([n_samples, original_dim], dtype=tf.float32)\n",
        "t_samples = tf.random.normal([n_samples, latent_dim], mean=0, stddev=1, dtype=tf.float32)\n",
        "sampled_im_mean = get_x_mean(decoder(t_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGEIuOsTINj7"
      },
      "outputs": [],
      "source": [
        "sampled_im_mean_np = sess.run(sampled_im_mean)\n",
        "# Show the sampled images.\n",
        "plt.figure(figsize = (15, 5))\n",
        "for i in range(n_samples):\n",
        "    ax = plt.subplot(n_samples // 5 + 1, 5, i + 1)\n",
        "    plt.imshow(sampled_im_mean_np[i, :].reshape(w_dim, h_dim, c_dim))\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdSx-ezKIUoS"
      },
      "source": [
        "## Задача 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7rzjUd-IUoT"
      },
      "source": [
        "\n",
        "**Задача 5.1** Здесь будет повторно внедрен CVAE модель, т.е. будут использованы  ```create_encoder``` и ```create_decoder```, определенные ранее (теперь вы можете понять, почему они принимают размер ввода в качестве аргумента ;) ). также будет использоваться слой Keras `concatenate` для объединения меток с входными данными и скрытым кодом.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE2fBdLEIUoX"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from PIL import Image\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "w_dim = x_train[0].shape[0]\n",
        "h_dim = x_train[0].shape[1]\n",
        "c_dim = x_train[0].shape[2]\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "x_train_ = x_train.astype('float32') / 255.\n",
        "x_test_ = x_test.astype('float32') / 255.\n",
        "\n",
        "\n",
        "x_train_ = x_train_.reshape(-1, w_dim * h_dim * c_dim)\n",
        "x_test_ = x_test_.reshape(-1, w_dim * h_dim * c_dim)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "del vae\n",
        "\n",
        "# Start tf session so we can run code.\n",
        "#sess = tf.InteractiveSession()\n",
        "sess=tf.compat.v1.InteractiveSession()\n",
        "# Connect keras to the created session.\n",
        "K.set_session(sess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRBjmr-BIUoV"
      },
      "outputs": [],
      "source": [
        "batch_size = master_batch_size\n",
        "original_dim = x_train_.shape[1] # Number of pixels in  images.\n",
        "latent_dim = 10 # d, dimensionality of the latent code t.\n",
        "intermediate_dim = 256 # Size of the hidden layer.\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "label = Input(batch_shape=(batch_size, 10))\n",
        "\n",
        "def create_encoder2(input_dim):\n",
        "    # Encoder network.\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    encoder2 = Sequential(name='encoder2')\n",
        "    encoder2.add(InputLayer([input_dim], name = 'Inpute_encoder'))\n",
        "   # encoder.add(BatchNormalization())\n",
        "    encoder2.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoder'))\n",
        "    # encoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_encoder'))\n",
        "    # encoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_encoder'))\n",
        "    encoder2.add(Dense(2 * latent_dim, kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return encoder2\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "get_x_mean = Lambda(lambda h: h[:, :original_dim])\n",
        "get_x_var = Lambda(lambda h: h[:, original_dim:])\n",
        "\n",
        "encoder2 = create_encoder2(original_dim + 10)\n",
        "\n",
        "get_t_mean = Lambda(lambda h: h[:, :latent_dim])\n",
        "get_t_log_var = Lambda(lambda h: h[:, latent_dim:])\n",
        "get_x =  Lambda(lambda h: h[:, :original_dim])\n",
        "h = encoder2(tf.concat([x,label], 1))\n",
        "cond_t_mean = get_t_mean(h)\n",
        "cond_t_log_var = get_t_log_var(h)\n",
        "\n",
        "# Sampling from the distribution \n",
        "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
        "# with reparametrization trick.\n",
        "\n",
        "t = Lambda(sampling)([cond_t_mean, cond_t_log_var])\n",
        "\n",
        "# Sampling from the distribution \n",
        "#     q(t | x) = N(t_mean, exp(t_log_var))\n",
        "# with reparametrization trick.\n",
        "def sampling(args):\n",
        "    \"\"\"Returns sample from a distribution N(args[0], diag(args[1]))\n",
        "    \n",
        "    The sample should be computed with reparametrization trick.\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        args[0]: (batch_size x latent_dim) mean of the desired distribution\n",
        "        args[1]: (batch_size x latent_dim) logarithm of the variance vector of the desired distribution\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor of size (batch_size x latent_dim), the samples.\n",
        "    \"\"\"\n",
        "    t_mean, t_log_var = args\n",
        "    t_std = tf.exp(0.5*t_log_var)\n",
        "    #print(t_std)\n",
        "    eps = tf.random.normal(t_mean.shape, mean=0, stddev=1, dtype=tf.float32)*t_std + t_mean\n",
        "    return eps\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "\n",
        "t = Lambda(sampling)([cond_t_mean, cond_t_log_var])\n",
        "\n",
        "def create_decoder2(input_dim):\n",
        "    # Decoder network\n",
        "    # We instantiate these layers separately so as to reuse them later\n",
        "    decoder2 = Sequential(name='decoder2')\n",
        "    decoder2.add(InputLayer([input_dim], name = 'Inpute_decoder2'))\n",
        "    # decoder.add(Dense(intermediate_dim // 4, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_4_decoder'))\n",
        "    # decoder.add(Dense(intermediate_dim // 2, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_2_decodder'))\n",
        "    decoder2.add(Dense(intermediate_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), name = 'intermediate_dim_encoider'))\n",
        "    decoder2.add(Dense(2*original_dim, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
        "    return decoder2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "decoder2 = create_decoder2(latent_dim + 10)\n",
        "cond_x_decoded = decoder2(tf.concat([t,label] ,1))\n",
        "cond_x_decoded_mean = get_x_mean(cond_x_decoded)\n",
        "cond_x_decoded_var = get_x_var(cond_x_decoded)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vlb_binomial(x, x_decoded_mean,  x_decoded_var, t_mean, t_log_var):\n",
        "    \"\"\"Returns the value of negative Variational Lower Bound\n",
        "    \n",
        "    The inputs are tf.Tensor\n",
        "        x: (batch_size x number_of_pixels) matrix with one image per row with zeros and ones\n",
        "        x_decoded_mean: (batch_size x number_of_pixels) mean of the distribution p(x | t), real numbers from 0 to 1\n",
        "        t_mean: (batch_size x latent_dim) mean vector of the (normal) distribution q(t | x)\n",
        "        t_log_var: (batch_size x latent_dim) logarithm of the variance vector of the (normal) distribution q(t | x)\n",
        "    \n",
        "    Returns:\n",
        "        A tf.Tensor with one element (averaged across the batch), VLB\n",
        "    \"\"\"\n",
        "\n",
        "    #cce = tf.keras.losses.CategoricalCrossentropy(axis=1)\n",
        "    t_var =  tf.exp(t_log_var)\n",
        "    kl = -t_log_var/2.0 + (t_var + t_mean**2 - 1)/2.0\n",
        "    kl = tf.reduce_sum(kl, axis=1)\n",
        "    batch_size = x.shape[0]\n",
        "    number_of_pixels = x.shape[1]\n",
        "    latend_dim = t_mean.shape[1]\n",
        "\n",
        "    two_pi = tf.constant(2.0 * np.pi)      \n",
        "    #log_p = tf.keras.losses.binary_crossentropy(x, x_decoded_mean)                                                                                                                        \n",
        "    #log_p = -number_of_pixels/ 2.0 * tf.math.log(two_pi * tf.math.pow(x_decoded_var, 2.0) + 1e-6) -  tf.math.reduce_euclidean_norm(x_decoded_mean - x, axis=0) / (2.0 * tf.math.pow(x_decoded_var, 2.0)  + 1.0 * 1e-6)\n",
        "    log_p = -0.5 * (tf.math.log(two_pi) + tf.math.log(x_decoded_var + 1e-6) + tf.math.log(x_decoded_var + 1e-6) +  tf.math.divide_no_nan(tf.math.pow(tf.math.reduce_euclidean_norm(x_decoded_mean - x, axis=0), 2.0) , tf.math.pow(x_decoded_var, 2.0)) + 1.0 * 1e-6)\n",
        "    log_p = tf.reduce_sum(log_p, axis=1) \n",
        "\n",
        "    #result = tf.reduce_mean(number_of_pixels*log_p - kl) \n",
        "    result = tf.reduce_mean(log_p - kl) #* (x_train_.shape[0] / master_batch_size )\n",
        "    \n",
        "    print(\"batch_size = {}, number_of_pixels = {} kl_size = {}\".format(batch_size, number_of_pixels, kl.shape))\n",
        "    return -result"
      ],
      "metadata": {
        "id": "tsO7_JkfI31S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA4tLOn-IUoY"
      },
      "source": [
        "## Определение функции ошибки и модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB_tFr6tIUoZ"
      },
      "outputs": [],
      "source": [
        "conditional_loss = vlb_binomial(x, cond_x_decoded_mean , cond_x_decoded_var, cond_t_mean, cond_t_log_var)\n",
        "cvae = Model([x, label], cond_x_decoded_mean )\n",
        "cvae.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss=lambda x, y: conditional_loss)\n",
        "#cvae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\\\n",
        "#                amsgrad=False, name='Adam'), loss=lambda x, y: loss)\n",
        "tf.keras.utils.plot_model(cvae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idQ5nlybIUoZ"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jJdahh5IUoa"
      },
      "outputs": [],
      "source": [
        "save_filepath = '/tmp_cifar/checkpoint'\n",
        "\n",
        "hist = cvae.fit(x=[x_train_, y_train],\n",
        "                y=x_train_,\n",
        "                shuffle=True,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=([x_test_, y_test], x_test_), verbose=1, callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', mode = \"min\", verbose = 1, patience = 10)\n",
        "                                                                                      , tf.keras.callbacks.ModelCheckpoint(filepath = save_filepath, monitor = 'val_loss', mode = 'min', verbose = 1, save_best_only=True)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cvae.load_weights(save_filepath)"
      ],
      "metadata": {
        "id": "mcG4FiEvUEH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdQKLqlYIUob"
      },
      "source": [
        "### Визуализация реконструкции для обучения и проверки данных"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cond_x_decoded = cvae.get_layer('decoder2')"
      ],
      "metadata": {
        "id": "3ZrJVZQIUIpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9U6eiF-IUob"
      },
      "outputs": [],
      "source": [
        "\n",
        "for fid_idx, (x_data, y_data, title) in enumerate(\n",
        "            zip([x_train_, x_test_], [y_train, y_test], ['Train', 'Validation'])):\n",
        "    n = 10 \n",
        "    fig, ax = plt.subplots(n, 2, figsize=(10, 4 * n))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    ind = 0\n",
        "    decoded = sess.run(cond_x_decoded_mean,\n",
        "                       feed_dict={x: x_data[:batch_size, :],\n",
        "                                  label: y_data[:batch_size, :]})\n",
        "    for i in range(n):\n",
        "        ax[i][0].imshow(data[i, :].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][1].imshow(decoded[i, :original_dim].reshape(w_dim, h_dim, c_dim))\n",
        "        ax[i][0].set_title('Input')\n",
        "        ax[i][1].set_title('Mean Decode')\n",
        "        ax[i][0].axis('off')\n",
        "        ax[i][1].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hrgZSItIUoc"
      },
      "source": [
        "## Условные новые данные\n",
        "\n",
        "**Задание 5.2** Реализовать условное моделирование из распределения $p(x \\mid t, \\text{label})$, сначала выбирая из априорного $p(t)$, а затем выбирая из вероятности $p(x \\mid т, \\text{метка})$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxSSW6JbIUoe"
      },
      "outputs": [],
      "source": [
        "# Prepare one hot labels of form\n",
        "#   0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 ...\n",
        "# to sample five zeros, five ones, etc\n",
        "n_samples = 50\n",
        "curr_labels = np.eye(10)\n",
        "curr_labels = np.repeat(curr_labels, 5, axis=0)  # Its shape is 50 x 10.\n",
        "# YOUR CODE HERE.\n",
        "# ...\n",
        "# cond_sampled_im_mean is a tf.Tensor of size 50 x 784 with 5 random zeros,\n",
        "# then 5 random ones, etc sampled from the cvae model.\n",
        "#curr_labels.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKu3i5QwIUoe"
      },
      "outputs": [],
      "source": [
        "_mean = tf.zeros([n_samples, original_dim], dtype=tf.float32)\n",
        "_std =tf.ones([n_samples, original_dim], dtype=tf.float32)\n",
        "t_samples = tf.random.normal([n_samples, latent_dim], mean=0, stddev=1, dtype=tf.float32)\n",
        "curr_labels_tensor = tf.convert_to_tensor(curr_labels.tolist())\n",
        "cond_sampled_im_mean = decoder2(tf.concat([t_samples, curr_labels_tensor],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwsUfQ1RIUoe"
      },
      "outputs": [],
      "source": [
        "cond_sampled_im_mean_np = sess.run(cond_sampled_im_mean)\n",
        "# Show the sampled images.\n",
        "plt.figure(figsize=(10, 10))\n",
        "global_idx = 0\n",
        "for digit in range(10):\n",
        "    for _ in range(5):\n",
        "        ax = plt.subplot(10, 5, global_idx + 1)\n",
        "        plt.imshow(cond_sampled_im_mean_np[global_idx, :original_dim].reshape(32, 32, 3))\n",
        "        ax.axis('off')\n",
        "        global_idx += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (15, 10))\n",
        "\n",
        "\n",
        "train_loss = np.concatenate([hist.history['loss'], hist2.history['loss']])\n",
        "\n",
        "plt.plot(train_loss, label = 'Train Loss')\n",
        "\n",
        "\n",
        "test_loss = np.concatenate([hist.history['val_loss'], hist2.history['val_loss']])\n",
        "\n",
        "plt.plot(test_loss, label = 'Test Loss')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "zMZSbVeVkwD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PndziE0lQOL"
      },
      "source": [
        "**Обязательная часть**\n",
        "* Повторить задание 1-4 для смеси распределений Гаусса (см. лекцию). Добавить раннюю остановку (early stopping)\n",
        "* Получить выражение для VLB (Задание 1)\n",
        "* Изучить влияние параметров на качество восстановления (Поварьировать параметры обучения, структуру сетей и пр.) \n",
        "\n",
        "**Дополнительно**\n",
        "* Повторить задание 5\n",
        "* Изучить влияние параметров на качество восстановления (Поварьировать параметры обучения, структуру сетей и пр.) \n",
        "* Реализовать для 1-5 сверточные слои в нейронной сети. Проанализировать результат."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iFmoB1aS3KIZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Копия блокнота \"lr2 .ipynb\"",
      "provenance": []
    },
    "interpreter": {
      "hash": "1da112943956fe70477526553c53af9fb2cedd581d0861db4fbae19f01c96c83"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tensflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}